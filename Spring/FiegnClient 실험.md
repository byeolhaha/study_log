## 개요
외부 서비스에 전적으로 의존하는 채팅 서비스를 개발하게 되었다. 이 서비스는 사용자가 메시지를 입력할 때마다 외부 API를 호출하는 구조이기 때문에, 다음과 같은 고려사항들이 필요했다

- 트랜잭션 분리 여부: 외부 서비스 호출이 내부 DB 트랜잭션 안에 포함되어 있는지 확인이 필요했고, 만약 분리되어 있다면 외부 호출 실패 시 이미 커밋된 트랜잭션에 대해 어떻게 후속 조치를 할 것인지 고민해야 했다.
- Tomcat 스레드 점유: 외부 호출이 오래 걸릴 경우, Tomcat의 처리 스레드를 장시간 점유하게 되어 다른 요청에 영향을 줄 수 있으므로, 이를 방지할 방안도 고려했다.
- HTTP 커넥션 풀 관리: 빈번하게 외부 호출이 발생하는 만큼, FeignClient가 사용하는 HTTP 클라이언트의 커넥션 풀 설정이 적절한지 확인이 필요했다.
- 타임아웃 설정: 외부 서비스 장애나 지연 상황을 대비해 커넥션 타임아웃, 읽기 타임아웃 값이 합리적으로 설정되어 있는지 검토했다.
  
이런 점들을 확인하며 자연스럽게 현재 사용 중인 FeignClient의 동작 방식과 기본 설정을 깊이 있게 살펴볼 필요성을 느끼게 되었다. 그 과정에서 다음과 같은 의문들이 생겼다
- FeignClient의 기본 설정은 커넥션 풀 없이, 요청마다 3-way 핸드셰이크를 거치는 것인가? Apache HttpClient를 설정하면 정말 커넥션 재사용률이 높아질까?
- FeignClient 사용하는 기본 URLConnection은 내부적으로 커넥션을 캐싱하지만, 이 캐시 관리 과정에서 synchronized를 사용해 락 병목이 생길 수 있다는 말은 사실인가?
- 서버의 keep-alive 시간보다 클라이언트의 TTL이 더 길면, 죽은 커넥션을 사용하다 예외가 발생하는가?

이러한 의문들을 바탕으로, 실제로 어떤 설정이 시스템에 어떤 영향을 미치는지 실험을 통해 검증해보고, 운영 환경에서 어떤 부분을 신경 써야 할지 정리해보고자 한다.

## FeignClient의 기본 설정은 커넥션 풀 없이, 요청마다 3-way 핸드셰이크를 거치는 것인가? Apache HttpClient를 설정하면 정말 커넥션 재사용률이 높아질까?
FeignClient는 기본적으로 HttpURLConnection을 사용하는데, 이는 내부적으로 keepAliveCache를 통해 커넥션 재사용을 시도하긴 하지만, 실제 테스트에서는 요청 대부분이 3-way 핸드셰이크를 동반하는 것으로 나타났다.
이는 재사용이 전혀 되지 않는다는 의미보다는, 기본 캐시 크기가 작고 재사용 조건이 제한적이어서 마치 커넥션 풀이 없는 것처럼 보이는 것이다.

예를 들어, JDK 기본 설정에서는 keepAliveCache의 커넥션 저장 개수가 destination (host + port) 기준으로 단 5개에 불과하다.
또한, 서버가 keep-alive를 허용하지 않거나, 서버측에서 커넥션을 먼저 종료해버리는 경우에도 재사용이 불가능하다.

![화면 기록 2025-07-26 오후 11 49 30](https://github.com/user-attachments/assets/f1584dc8-e0fa-4fd7-8b31-146a82f5db6c)

Apache HttpClient를 설정하면 정말 커넥션 재사용률이 높아지는지
아래 화면 기록을 보면 위 기록과 다르게 3-way 핸드셰이크가 초반에만 일어나고 그 이후에는 잠잠하다.


## FeignClient가 사용하는 기본 URLConnection은 내부적으로 커넥션을 캐싱하지만, 이 캐시 관리 과정에서 synchronized를 사용해 락 병목이 생길 수 있다는 말은 사실인가?
나는 FeignClient의 커넥션 재사용에 대해 조사하던 중, 토스의 기술 블로그(https://toss.tech/article/engineering-note-3)를 통해 HttpURLConnection의 내부 구현에 synchronized가 사용된다는 내용을 접했다.
하지만 실제로 JDK 소스를 확인해보니, 해당 부분은 이미 ReentrantLock 기반으로 변경되어 있었다.

이 변화가 왜 일어났는지 궁금해졌다.
나는 개인적으로 synchronized와 ReentrantLock 간의 성능 차이를 직접 실험해보았지만, 단순 경쟁 조건에서는 유의미한 차이가 없었기 때문에 더 의문이 들었다.

그래서 찾아본 결과, 다음과 같은 배경이 있음을 알게 되었다. (정확하지 않을 수도 있음)
가장 핵심적인 이유는 가상 스레드(virtual thread) 환경에서의 호환성이다. JDK 21부터 본격적으로 도입된 가상 스레드는 OS 스레드가 아닌 사용자 공간의 경량 스레드로, 많은 수의 동시 작업을 효율적으로 처리할 수 있게 설계되었다.

그러나 synchronized는 다음과 같은 제약이 있다
- synchronized는 내부적으로 모니터 락을 사용하고, 이 락은 커널 수준에서 관리되는 OS 스레드를 기반으로 한다. ( 물론 처음에는 코드 수준의 경량락을 사용한다. 그런데 이 때 락을 획득하지 못하면 커널 수준으로 넘어간다.)
- 즉, 가상 스레드가 synchronized에 진입하면, 해당 가상 스레드는 더 이상 커널에서 분리된 lightweight가 아니게 되고, 커널 수준 스레드로 블로킹된다.
- 이는 가상 스레드의 효율성을 무력화시켜 수십만 개의 경량 스레드를 동시에 유지하고자 하는 목적에 반한다.

반면 ReentrantLock은
- Java 코드 기반의 명시적인 락 구현이며, 내부적으로 LockSupport.park() 같은 메커니즘을 사용해 스레드를 주도적으로 parking 할 수 있다.
- 이러한 방식은 가상 스레드가 블로킹 상태에 진입하더라도, 실제로는 커널 스레드가 아닌 가상 스레드 자체를 안전하게 parking 시켜 리소스를 아낄 수 있게 해준다. 
- 따라서 최근 JDK에서는 가상 스레드와의 호환성을 위해 내부적으로 synchronized를 ReentrantLock으로 대체하는 사례가 늘어나고 있으며, HttpURLConnection의 keepAliveCache 역시 이러한 흐름을 따른 것으로 보인다.

이 둘의 동작 방식에 대해서는 https://velog.io/@byeolhaha/Java-%EB%9D%BD-%EB%8F%99%EA%B8%B0%ED%99%94%EC%97%90-%EB%8C%80%ED%95%98%EC%97%AC 이 글에 정리해놓았다.

## 서버의 keep-alive 시간보다 클라이언트의 TTL이 더 길면, 죽은 커넥션을 사용하다 예외가 발생하는가?


<img width="2014" height="1294" alt="image" src="https://github.com/user-attachments/assets/cbf414ad-379c-4293-b545-7a272d2be7c5" />

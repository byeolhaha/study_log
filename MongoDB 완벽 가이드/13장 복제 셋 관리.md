# 13장 복제 셋 관리
## 유지보수 작업을 할 때는 독립 실행형 서버로 전환하기
책에 말이 좀 어렵게 나와있는데
결국 한 서버가 복제 셋이면 유지보수 작업이 성능에 영향을 주기 때문에 복제셋에서 분리 시켜 독립 실행형 서버로 전환해서 유지보수 작업을 진행하고 다시 복제셋에 합류시키라는 이야기이다.

몇 가지 절차가 있는데 먼저

1. 아래 명령어를 통해서 해당 서버의 정보를 얻는다.
  ```
mdbDefGuide [direct: primary] test> db.serverCmdLineOpts()
{
  argv: [
    'mongod',
    '--replSet',
    'mdbDefGuide',
    '--dbpath',
    '/Users/kimbyeol/data/rs3',
    '--port',
    '27020',
    '--logpath',
    '/Users/kimbyeol/data/rs3/mongod.log'
  ],
  parsed: {
    net: { port: 27020 },
    replication: { replSet: 'mdbDefGuide' },
    storage: { dbPath: '/Users/kimbyeol/data/rs3' },
    systemLog: {
      destination: 'file',
      path: '/Users/kimbyeol/data/rs3/mongod.log'
    }
  },
  ok: 1,
  '$clusterTime': {
    clusterTime: Timestamp({ t: 1726903508, i: 1 }),
    signature: {
      hash: Binary.createFromBase64('AAAAAAAAAAAAAAAAAAAAAAAAAAA=', 0),
      keyId: Long('0')
    }
  },
   operationTime: Timestamp({ t: 1726903508, i: 1 })
 }

  ```
 결과를 해석해보면 아래와 같다.

 - argv (명령줄 인수):
   1. 'mongod': MongoDB 데몬(mongod) 실행 파일을 실행했다는 것을 나타냅니다.
   2. '--replSet', 'mdbDefGuide': MongoDB가 복제 셋(replica set) 모드로 실행되고 있으며, 복제 셋의 이름은 'mdbDefGuide'입니다.
   3. '--dbpath', '/Users/kimbyeol/data/rs3': MongoDB 데이터 파일이 저장되는 경로가 /Users/kimbyeol/data/rs3라는 것을 나타냅니다.
   4. '--port', '27020': MongoDB가 27020 포트에서 실행되고 있습니다.
   5. '--logpath', '/Users/kimbyeol/data/rs3/mongod.log': 로그 파일은 /Users/kimbyeol/data/rs3/mongod.log에 기록됩니다.
 - parsed (분석된 설정):
  - net.port: 네트워크 포트가 27020임을 나타냅니다.
  - replication.replSet: 복제 셋의 이름이 'mdbDefGuide'로 설정되어 있습니다.
  - storage.dbPath: 데이터가 저장되는 경로가 /Users/kimbyeol/data/rs3입니다.
  - systemLog.path: 로그 파일이 /Users/kimbyeol/data/rs3/mongod.log에 저장됩니다.
 - ok: 1:
 이 값은 명령이 성공적으로 실행되었음을 나타냅니다.
 - $clusterTime, operationTime:
  이 섹션은 MongoDB가 클러스터 환경에서 시간 동기화를 유지하기 위해 사용하는 타임스탬프 관련 정보입니다. 클러스터 타임(clusterTime)과 특정 작업의 타임스탬프(operationTime)이 기록되어 있으며, 이는 MongoDB가 복제본 간의 데이터 일관성을 유지하기 위한 메커니즘의 일환입니다.

2. 해당 서버를 종료한다.
   ```
   db.shutdownServer()
   ```
3. 독립 실행형 서버로 실행한다.
   - replSet 옵션 없이 서버를 재시작
   - 기존 서버와 다른 포트
   - 서버 데이터를 조작하기 위해 dbpath는 그대로 유지
   ```
   mongod --port 30000 --dbpath /Users/kimbyeol/data/rs3
   {"t":{"$date":"2024-09-21T16:35:49.783+09:00"},"s":"I",  "c":"CONTROL",  "id":23285,   "ctx":"thread1","msg":"Automatically disabling TLS 1.0, to force-enable TLS 1.0 specify --sslDisabledProtocols 'none'"}
   {"t":{"$date":"2024-09-21T16:35:49.785+09:00"},"s":"I",  "c":"NETWORK",  "id":4915701, "ctx":"thread1","msg":"Initialized wire specification","attr":{"spec":{"incomingExternalClient":{"minWireVersion":0,"maxWireVersion":21},"incomingInternalClient":{"minWireVersion":0,"maxWireVersion":21},"outgoing":{"minWireVersion":6,"maxWireVersion":21},"isInternalClient":true}}{"t":{"$date":"2024-09-21T16:35:50.055+09:00"},"s":"I",  "c":"STORAGE",  "id":5380103, "ctx":"initandlisten","msg":"Unpin oldest timestamp request","attr":{"service":"_wt_startup","requestedTs":{"$timestamp":{"t":1726903683,"i":1}}}}
   {"t":{"$date":"2024-09-21T16:35:50.055+09:00"},"s":"I",  "c":"FTDC",     "id":20625,   "ctx":"initandlisten","msg":"Initializing full-time diagnostic data capture","attr":{"dataDirectory":"/Users/kimbyeol/data/rs3/diagnostic.data"}}
   ...
   {"t":{"$date":"2024-09-21T16:35:50.057+09:00"},"s":"W",  "c":"CONTROL",  "id":20547,   "ctx":"initandlisten","msg":"Document(s) exist in 'system.replset', but started without --replSet. Database contents may appear inconsistent with the writes that were visible when this node was running as part of a replica set. Restart with --replSet unless you are doing maintenance and no other clients are connected. The TTL collection monitor will not start because of this. For more info see http://dochub.mongodb.org/core/ttlcollections","tags":["startupWarnings"]}
   {"t":{"$date":"2024-09-21T16:35:50.057+09:00"},"s":"W",  "c":"CONTROL",  "id":7692300, "ctx":"initandlisten","msg":"Replica set member is in standalone mode. Performing any writes will result in them being untimestamped. If a write is to an existing document, the document's history will be overwritten with the new value since the beginning of time. This can break snapshot isolation within the storage engine.","tags":["startupWarnings"]}
   ```
## 복제 셋 구성
복제 구성은 항상 local.system.replSet 컬렉션의 도큐먼트에 보관된다. **이 구성을 절대 update하지 말자**
대신 항상 rs보조자나 replSetReconfig 명령을 사용하자
```
mdbDefGuide [direct: primary] local> db.system.replset.find()
[
  {
    _id: 'mdbDefGuide',
    version: 6,
    term: 246,
    members: [
      {
        _id: 0,
        host: 'localhost:27018',
        arbiterOnly: false,
        buildIndexes: true,
        hidden: false,
        priority: 1,
        tags: {},
        secondaryDelaySecs: Long('0'),
        votes: 1
      },
      {
        _id: 1,
        host: 'localhost:27019',
        arbiterOnly: false,
        buildIndexes: true,
        hidden: true,
        priority: 0,
        tags: {},
        secondaryDelaySecs: Long('0'),
        votes: 1
      },
      {
        _id: 2,
        host: 'localhost:27020',
        arbiterOnly: false,
        buildIndexes: true,
        hidden: false,
        priority: 2,
        tags: {},
        secondaryDelaySecs: Long('0'),
        votes: 1
      },
      {
        _id: 4,
        host: 'localhost:27021',
        arbiterOnly: true,
        buildIndexes: true,
        hidden: false,
        priority: 0,
        tags: {},
        secondaryDelaySecs: Long('0'),
        votes: 1
      }
    ],
    protocolVersion: Long('1'),
    writeConcernMajorityJournalDefault: true,
    settings: {
      chainingAllowed: true,
      heartbeatIntervalMillis: 2000,
      heartbeatTimeoutSecs: 10,
      electionTimeoutMillis: 10000,
      catchUpTimeoutMillis: -1,
      catchUpTakeoverDelayMillis: 30000,
      getLastErrorModes: {},
      getLastErrorDefaults: { w: 1, wtimeout: 0 },
      replicaSetId: ObjectId('66e67d6975b425d31ae76217')
    }
  }
]
```
### 복제 셋 멤버 교체하기
- 복제 셋 추가할 때, 해당 복제 셋은 데이터가 하나도 없거나 다른 멤버의 복제본을 가지고 있는 상태여야 한다.
  ```
  rs.add("spock:27017")
  ```
  혹은 더 구체적으로 적을 수도 있음
  ```
  rs.add({"host":"spock:27017", "priority":0, "hidden":true})
  ```
- 재구성을 통해 설정 바꿀 때 아래의 제약사항이 존재한다.
  - 멤버의 _id는 바꿀 수 없다.
  - 재구성 정보를 전달하려는 멤버(일반적으로 프라이머리)의 우선순위를 0으로 할 수 없다.
  - 아비터는 아비터가 아닌 멤버로 바꿀 수 없다.
  - 멤버의 "buildIndexs"(프라이머리의 인덱스를 그대로 가져오는 옵션)을 false로 했다가 true로 바꿀 수 없다.
  - host 필드는 변경할 수 있다.
    ```
    var config = rs.config()
    config.members[0].host = "spock:27023"
    rs.reconfig(config)
    ```
### 큰 복제 셋 만들기
- 복제 셋 멤버는 50개
- 투표 멤버는 7개
- 위와 같이 제한하는 이유는 하트비트를 보내는 데 필요한 네트워크 트래픽 량을 줄이고 선출하는데 걸리는 시간을 줄이기 위함이다.
- 따라서 복제 셋 멤버가 7개 이상을 생성한다면 그 이후 즉 8번째 멤버부터는 투표권을 0개를 줘야 한다.
  ```
  rs.add({"_id":7,"host":"server-7:27017","votes":0})
  ```
### 재구성 강제하기
과반수를 넘지않아 모두 세컨더리인 경우에 구성을 변경하고 이를 반영하려면 재구성을 강제해야 한다.
```
rs.reconfig(config,{"force":true})
```

이러한 강제 재구성은 설정 파일의 "version"필드의 값을 크게 높인다.
## 멤버 상태 조작
### 프라이머에서 세컨더리로 변경
```
rs.stepDown()
```
저렇게 하면 60초 동안 세컨더리로 강등된다. 그 기간동안 다른 멤버가 프라이머리로 선출된다. 하지만 선출되지 않는다면 다시 프라이머리로 재선출되기를 시도한다.

더 길게 설정할 수도 있다.
```
rs.stepDown(600)//10분
```
### 선출 방지하기
프라머리에서 유지보수 작업을 하기 위해서 독립 실행형 서버로 바꾸고
그 사이에 다른 세컨더리들이 프리어미로 선출되지 않도록
각각 세컨더리 멤버에 freeze 명령을 실행할 수 있다.

```
rs.freeze(10000)
```
그러고 나서 유지보수 작업을 마치면
```
rs.freeze(0)
```

## 복제 모니터링
- 모든 멤버가 정상적으로 기동했는지
- 멤버가 어떤 상태인지
- 복제가 얼마나 최신 상태인지
- 복제와 관련된 문제는 일시적일 때가 많음
- 로그를 확인하면 문제를 쉽게 볼 수 있으므로 로그가 어디에 저장되고 있는지 확인하자

### 상태 정보 가져오기
앞서 배운 rs.status()로 확인이 가능하다.
```
mdbDefGuide [direct: primary] local> rs.status()
{
  set: 'mdbDefGuide',
  date: ISODate('2024-09-21T08:43:12.854Z'),
  myState: 1,
  term: Long('246'),
  syncSourceHost: '',
  syncSourceId: -1,
  heartbeatIntervalMillis: Long('2000'),
  majorityVoteCount: 3,
  writeMajorityCount: 3,
  votingMembersCount: 4,
  writableVotingMembersCount: 3,
  optimes: {
    lastCommittedOpTime: { ts: Timestamp({ t: 1726908183, i: 1 }), t: Long('246') },
    lastCommittedWallTime: ISODate('2024-09-21T08:43:03.359Z'),
    readConcernMajorityOpTime: { ts: Timestamp({ t: 1726908183, i: 1 }), t: Long('246') },
    appliedOpTime: { ts: Timestamp({ t: 1726908183, i: 1 }), t: Long('246') },
    durableOpTime: { ts: Timestamp({ t: 1726908183, i: 1 }), t: Long('246') },
    lastAppliedWallTime: ISODate('2024-09-21T08:43:03.359Z'),
    lastDurableWallTime: ISODate('2024-09-21T08:43:03.359Z')
  },
  lastStableRecoveryTimestamp: Timestamp({ t: 1726908173, i: 1 }),
  electionCandidateMetrics: {
    lastElectionReason: 'priorityTakeover',
    lastElectionDate: ISODate('2024-09-21T07:52:02.049Z'),
    electionTerm: Long('246'),
    lastCommittedOpTimeAtElection: { ts: Timestamp({ t: 1726905114, i: 1 }), t: Long('245') },
    lastSeenOpTimeAtElection: { ts: Timestamp({ t: 1726905114, i: 1 }), t: Long('245') },
    numVotesNeeded: 3,
    priorityAtElection: 2,
    electionTimeoutMillis: Long('10000'),
    priorPrimaryMemberId: 0,
    numCatchUpOps: Long('0'),
    newTermStartDate: ISODate('2024-09-21T07:52:02.069Z'),
    wMajorityWriteAvailabilityDate: ISODate('2024-09-21T07:52:02.090Z')
  },
  members: [
    {
      _id: 0,
      name: 'localhost:27018',
      health: 1,
      state: 2,
      stateStr: 'SECONDARY',
      uptime: 3080,
      optime: { ts: Timestamp({ t: 1726908183, i: 1 }), t: Long('246') },
      optimeDurable: { ts: Timestamp({ t: 1726908183, i: 1 }), t: Long('246') },
      optimeDate: ISODate('2024-09-21T08:43:03.000Z'),
      optimeDurableDate: ISODate('2024-09-21T08:43:03.000Z'),
      lastAppliedWallTime: ISODate('2024-09-21T08:43:03.359Z'),
      lastDurableWallTime: ISODate('2024-09-21T08:43:03.359Z'),
      lastHeartbeat: ISODate('2024-09-21T08:43:11.194Z'),
      lastHeartbeatRecv: ISODate('2024-09-21T08:43:11.599Z'),
      pingMs: Long('0'),
      lastHeartbeatMessage: '',
      syncSourceHost: 'localhost:27020',
      syncSourceId: 2,
      infoMessage: '',
      configVersion: 6,
      configTerm: 246
    },
    {
      _id: 1,
      name: 'localhost:27019',
      health: 1,
      state: 2,
      stateStr: 'SECONDARY',
      uptime: 3080,
      optime: { ts: Timestamp({ t: 1726908183, i: 1 }), t: Long('246') },
      optimeDurable: { ts: Timestamp({ t: 1726908183, i: 1 }), t: Long('246') },
      optimeDate: ISODate('2024-09-21T08:43:03.000Z'),
      optimeDurableDate: ISODate('2024-09-21T08:43:03.000Z'),
      lastAppliedWallTime: ISODate('2024-09-21T08:43:03.359Z'),
      lastDurableWallTime: ISODate('2024-09-21T08:43:03.359Z'),
      lastHeartbeat: ISODate('2024-09-21T08:43:11.194Z'),
      lastHeartbeatRecv: ISODate('2024-09-21T08:43:11.193Z'),
      pingMs: Long('0'),
      lastHeartbeatMessage: '',
      syncSourceHost: 'localhost:27018',
      syncSourceId: 0,
      infoMessage: '',
      configVersion: 6,
      configTerm: 246
    },
    {
      _id: 2,
      name: 'localhost:27020',
      health: 1,
      state: 1,
      stateStr: 'PRIMARY',
      uptime: 3081,
      optime: { ts: Timestamp({ t: 1726908183, i: 1 }), t: Long('246') },
      optimeDate: ISODate('2024-09-21T08:43:03.000Z'),
      lastAppliedWallTime: ISODate('2024-09-21T08:43:03.359Z'),
      lastDurableWallTime: ISODate('2024-09-21T08:43:03.359Z'),
      syncSourceHost: '',
      syncSourceId: -1,
      infoMessage: '',
      electionTime: Timestamp({ t: 1726905122, i: 1 }),
      electionDate: ISODate('2024-09-21T07:52:02.000Z'),
      configVersion: 6,
      configTerm: 246,
      self: true,
      lastHeartbeatMessage: ''
    },
    {
      _id: 4,
      name: 'localhost:27021',
      health: 1,
      state: 7,
      stateStr: 'ARBITER',
      uptime: 3080,
      lastHeartbeat: ISODate('2024-09-21T08:43:11.194Z'),
      lastHeartbeatRecv: ISODate('2024-09-21T08:43:11.194Z'),
      pingMs: Long('0'),
      lastHeartbeatMessage: '',
      syncSourceHost: '',
      syncSourceId: -1,
      infoMessage: '',
      configVersion: 6,
      configTerm: 246
    }
  ],
  ok: 1,
  '$clusterTime': {
    clusterTime: Timestamp({ t: 1726908183, i: 1 }),
    signature: {
      hash: Binary.createFromBase64('AAAAAAAAAAAAAAAAAAAAAAAAAAA=', 0),
      keyId: Long('0')
    }
  },
  operationTime: Timestamp({ t: 1726908183, i: 1 })
}
```
각각 무엇을 의미하는지 살펴보자
- self : rs.status()를 실행시킨 멤버에 존재하는 필드이다.
- stateStr : 서버의 상태를 나타내는 문자열
- uptime : 멤버에 도달할 수 있었던 시간(초) 혹은 이 서버가 self멤버를 위해 시작된 이후부터의 시간(초)
- optimeDate : 각 멤버의 oplog에서 마지막 연산 수행 시각
- lastHeartbeat : 서버가 self 멤버로부터 마지막으로 하트비트를 받은 시간, 네트워크에 문제가 있거나 서버가 분주하면 2초보다 길 수도 있다.
- pingMs : 이 서버에 대한 하트비트에 걸린 평균 시간, 어느 멤버로부터 동기화할지 결정하는 데 사용
- errmsg : 멤버가 하트비트 요청에 반환하기로 선택한 모든 상태 메세지, 전달용 ⭕️, 오류메시지 ❌

### 복제 그래프 시각화하기
책에서는 세컨더리에서 rs.status()의 syncingTo필드를 통해서 자신이 어디서 복제되었는지 확인할 수 있다고 하는데
이는 잘못된 내용이다.
일단 세컨더리에서 rs.status()를 하지 않고 프라이머리에서 해도 ```syncSourceHost```필드를 통해서 확인가능하며
세컨더리에서 확인한다고 해도 책에서 언급한 ```syncingTo```필드는 존재하지 않고 ```syncSourceHost```필드를 통해서 확인가능하다.
```
mdbDefGuide [direct: other] test> rs.status()
{
  set: 'mdbDefGuide',
  date: ISODate('2024-09-21T08:51:43.424Z'),
  myState: 2,
  term: Long('246'),
  syncSourceHost: 'localhost:27018',
  syncSourceId: 0,
```

복제 그래프 알아내기
```
mdbDefGuide [direct: other] test> db.adminCommand({replSetGetStatus:1})['syncSourceHost']
localhost:27018
```

프라이머리는 없음
```
mdbDefGuide [direct: primary] local> db.adminCommand({replSetGetStatus:1})['syncSourceHost']

```

앞서 rs.status()필드 중에서 pingMs를 통해서 동기화할 대상을 정한다고 배웠다.
멤버는 다른 멤버에 하트비트를 보낼 때 요청이 처리되기까지 걸리는 시간을 잰다.

즉 동기화할 멤버는 선택할 때
- 가장 가깝고
- 복제에서 자신보다 앞서 있는 멤버를 찾는다.

그렇기 때문에 데이터 센터에 새로운 세컨더리가 추가된다고 한다면
아래의 그림이 완성된다.
![image](https://github.com/user-attachments/assets/fd3bdc47-a664-4c37-875c-0a05c2dc8c5f)


하지만 자동 복제 사슬의 단점이 있는데
복제 홉이 많을 수도 모든 서버에 쓰기를 복제하는데 시간이 오래걸린다.
예를 들어 모든 멤버가 하나의 데이터 선터에 있지만
멤버를 추가할 때 네트워크 속도가 갑자기 변해서 일렬로 복제하는 상황이 발생할 수도 있다.
![image](https://github.com/user-attachments/assets/8796d90c-a637-4978-adbc-907063dc9aa6)

따라서 이런 상황이 만들어진다면 수동으로 복제 소스를 수정하자
```
db.adminCommand({"replSetSyncFrom":"localhost:27019"})
```

### 복제 루프
![image](https://github.com/user-attachments/assets/beec0275-edb5-4f46-a92b-b82d3d7f46b0)
위 상황을 만들지 않도록 아래 명령어 수행시 조심하자
복제루프를 만들면 모든 멤버는 프라이머리가 될 수없다. 클러스터 전체에서 프라이머리를 선출하는 과정이 실패하거나 잘못된 방식으로 동작할 수 있습니다.
```
db.adminCommand({"replSetSyncFrom":"localhost:27019"})
```
### 복제 사슬 비활성화하기 -> 모두 프라이머리를 복제소스로
```
var config = rs.status()
config.settins.chainingAllowed = false
rs.reconfig(config)
```

만약에 프라이머리가 이용 불가능한 상태가 되면 세컨더리와 동기화한다.

### 지연 계산하기
멤버의 복제 상태 보기
- 프라이머리의 oplog 요약 상태 보기
  ```
  mdbDefGuide [direct: primary] local> rs.printReplicationInfo()
  actual oplog size
  '192 MB'
  ---
  configured oplog size
  '192 MB'
  ---
  log length start to end
  '530397 secs (147.33 hrs)'
  ---
  oplog first event time
  'Sun Sep 15 2024 15:23:37 GMT+0900 (대한민국 표준시)'
  ---
  oplog last event time
  'Sat Sep 21 2024 18:43:34 GMT+0900 (대한민국 표준시)'
  ---
  now
  'Sat Sep 21 2024 18:43:40 GMT+0900 (대한민국 표준시)'
  ```
  oplog의 사이즈는 전체적으로 재동기화하는 데 걸리는 시간만큼 길면 좋다.
  왜냐하면 그게 다 채워지면 다시 왼쪽부터 가장 오래된 데이터를 삭제하기 때문이다.
  만약에 크기가 재동기화하는 시간만큼이라면 삭제가 발생하지 않지만
  크기가 작다면 왼쪽에서부터 삭제될 것이고 어느 순간에는 세컨더리가 복제해야 하는 데이터마저 삭제할지도 모른다.
- 세컨더리의 복제 소스와 마지막 oplog항목이 각 세컨더리에 기록된 시간 보기
  ```
  mdbDefGuide [direct: primary] local> rs.printSlaveReplicationInfo()
  MongoshDeprecatedError: [COMMON-10003] printSlaveReplicationInfo has been deprecated. Use printSecondaryReplicationInfo instead
  mdbDefGuide [direct: primary] local> rs.printSecondaryReplicationInfo()
  source: localhost:27018
  {
    syncedTo: 'Sat Sep 21 2024 18:48:04 GMT+0900 (대한민국 표준시)',
    replLag: '0 secs (0 hrs) behind the primary '
  }
  ---
  source: localhost:27019
  {
    syncedTo: 'Sat Sep 21 2024 18:48:04 GMT+0900 (대한민국 표준시)',
    replLag: '0 secs (0 hrs) behind the primary '
  }
  ```

  다음 상황을 상상해 봐라
  
  >프라이머리에서 한 시간에 한 번 쓰기 작업이 발생하고, 이 쓰기 작업은 세컨더리로 복제되어야 합니다.
  만약 프라이머리가 쓰기 작업을 한 직후 세컨더리가 아직 그 변경 사항을 복제하지 않았다면, 세컨더리는 한 시간 뒤처진 것처럼 보입니다.
  하지만 실제로는 쓰기 작업이 거의 없기 때문에, 세컨더리가 복제해야 할 내용은 아주 적습니다. 세컨더리는 이 작은 데이터를 몇 초 혹은 몇 밀리초 안에 쉽게 따라잡을 수 있습니다.
  
  ** 즉, 시스템을 모니터링할 때 세컨더리가 한 시간이나 뒤처진 것처럼 보일 수 있지만, 사실은 세컨더리가 빠르게 복제하고 있고 실제 지연은 거의 없다. 이런 상황은 특히 쓰기 작업이 거의 없는 시스템에서 발생할 수 있으며, 이를 보고 복제 지연이 크다고 착각할 수 있다.**

## Oplog 크기 변경하기
프라이머리의 oplog = 세컨더리의 유지 보수 시간
>**"프라이머리의 oplog 길이가 한 시간 정도라면 잘못된 부분을 고칠 수 있는 시간이 한 시간 정도다"**라는 말은, 만약 세컨더리 노드가 동기화 과정에서 문제가 발생하거나 복제 지연이 생기더라도, 최대 1시간 이내에 이를 고칠 수 있는 시간적 여유가 있다는 뜻입니다.
즉, 세컨더리 노드가 복제를 따라가지 못하더라도 1시간 안에 문제를 해결하고 복제를 재개할 수 있다면, 프라이머리에서 발생한 데이터 변경 사항을 복제할 수 있다는 것입니다. 그러나 1시간이 넘으면 oplog에서 더 이상 이전 데이터를 복제할 수 없고, 세컨더리는 전체 데이터를 다시 동기화해야 할 수도 있습니다.

왜냐하면 1시간이 지나면 프라이머리의 oplog의 오래된 데이터순으로 점차 삭제되고 이를 다시 덮어씌워 사용하기 때문이다.
따라서 충분히 큰 oplog 사이즈를 설정하자.

와이어드타이거 스토리지 엔진을 사용한다면 서버를 사용하는 동안에 oplog 크기를 변경할 수 있다.

### 인덱스 구축하기
프라이머리에 인덱스를 구축하면
세컨더리는 ```build index```연산을 복제할 때 구축한다.
하지만 인덱스 구축은 멤버를 이용 불가능한 상태로 만들 수 있다.

만약에 동시 다발적으로 세컨더리가 인덱스를 구축하면 복제 셋의 모든 멤버가 오프라인 상태가 된다.
따라서 차례차례 세컨더리에 인덱스를 구축하자. 방법은 아래와 같다.
1. 세컨더리 종료
2. 종료한 세컨더리를 독립 실행형 서버로 재시작
3. 인덱스 구축
4. 복제 셋 멤버로 재시작, 멤버를 재시작할 때 명령행 옵션이나 구성 파일에 disableLogicalSessionCacheRefresh매개 변수가 있으면 제거해야 한다.
5. 복제 셋의 각 세컨더리에 1단계부터 4단계까지 반복한다.


이제부터는 프라이머리를 제외한 모든 세컨더리에 인덱스가 구축되었으며 이제 프라이머리에 각 서비스 특징에 맞게 선택하자.
- 첫 번째 방법
  프라이머리에 인덱스를 구축한다. 트래픽이 적을 때 오프 시간을 가질 수 있다면 이 때 구축, 또한 읽기 선호도를 수정해서 구축이 진행중일 때는 세컨더리로 가도록
- 두 번째 방법
  프라이머리를 강등한 후 앞서 언급한 세컨더리에 인덱스를 구축하는 방법으로 인덱스를 구축, => 이 때는 어차피 강등되어서 다른 프라이어미가 선출되어져 있다.


혹은 완전히 다른 관점으로 세컨더리에서 다른 복제 셋 멤버의 인덱스와 다르게 인덱스를 구축할 수도 있다.
다만 이 멤버는 절대 프라이머리가 될 수 없으며 우선순위가 0이다.

**고유 인덱스를 고축할 때**는 프라이머리가 중복 삽입을 하지 않아야 한다. 따라서 프라이머리부터 먼저 구축하자!
그렇지 않으면 프라이머리는 중복 삽입을 하게 되고 세컨더리는 복제 오류를 발생시킨다.
이러한 오류가 발생하면 세컨더리는 스스로 종료하며, 독립 실행형 서버로 재시작해서 고유 인덱스를 삭제한후 다시 시작해야 한다.

### 한정된 예산에서 복재하기
좋은 서버는 프라이머리
상대적으로 값싼 서버는 재해 복구용 세컨더리

값싼 서버를 설정하기 위한 옵션
- ```"priority":0``` :  절대 해당 서버가 프라이머리가 되지 않도록
- ```"hidden":true```: 클라이언트가 해당 세컨더리로 읽기 요청을 보내지 않도록
- ```"buildIndexes": false``` : 선택적이지만, 해당 서버가 처리해야 하는 부하를 상당히 줄여준다. 하지만 이 서버로부터 복원할 경우 인덱스를 재구축해야 한다.
- ```"votes":0``` : 서버가 두 개뿐이라면 프라이머리가 다운되더라도 프라이머로 유지되도록, 만약에 3개라면 votes를 0으로 실행하는 대신 아비터를 실행한다.
  여기서 나는 마지막 말이 이해되지 않았는데 책에서는 분명 아비터를 사용하지 않는 것이 바람직하다라고 말했으면서 왜 갑자기 여기서 사용하라는 걸까라는 의문이 있었다.
  그래서 챗지피티에 물어보니까
  >값싼 서버를 재해 복구용으로 사용하면서, 프라이머리의 선출 문제를 해결하기 위해 아비터를 고려할 수 있다는 것입니다. 여기서 주어진 예시에서는, 값싼 서버에 투표권(votes)을 0으로 설정하여 프라이머리가 되지 않도록 하고, 대신 아비터를 추가하여 과반수 투표권을 맞추는 해결책을 제시하는 것

이러한 세컨더리가 있다면 두 개의 고성능 서버 없이도 안정성과 보안성을 얻을 수 있다.
  

# 샤딩 구성
- 구성 서버, 샤드, mongos 프로세스 설정 방법
- 클러스터 용량 추가 방법
- 데이터 저장 및 분산 방법
## 언제 사용해야 하는가?
- 너무 일찍 샤딩한다면 : 배포 운영이 복잡해진다.
- 너무 늦게 샤딩한다면 : 과부하된 시스템을 중단 없이 샤딩하기 어렵다.
- 일반적인 샤딩은 다음과 같은 경우에 사용한다.
  - 사용 가능한 메모리를 늘릴 때
  - 사용 가능한 디스크 공간을 늘릴 때
  - 서버의 부하를 줄일 때
  - 한 개의 mongod가 다룰 수 있는 처리량보다 더 많이 데이터를 읽거나 쓸 때
- 따라서 샤딩이 필요한 시점을 결정하는 데 모니터링이 중요하다.
- 일반적으로 여러 병목 중 한가지를 맞닥뜨리게 되는데 어떤 항목을 미리 준비해 놓을 지 찾고, 복제 셋 전환 방법과 시기를 미리 계획해야 한다.

## 서버 시작
### 구성 서버
- 클러스터의 두뇌부
- 어떤 서버가 무슨 데이터를 갖고 있는지에 대한 모든 메타 데이터를 보유하고 있다.
- 구성 서버를 제일 먼저 설정
- 구성 서버의 복제 셋은 3개 이상의 멤버로 구성
- 각 구성 서버는 지리적으로 분산된 별도의 물리 장비에 있어야 한다.
    ```
   mongod --configsvr --replSet configReplSet --port 37019 --dbpath /Users/kimbyeol/data/configdb  --bind_ip localhost
   ```

   ```
   mongod --configsvr --replSet configReplSet --port 37031 --dbpath /Users/kimbyeol/data/configdb_1  --bind_ip localhost
   ```

   ```
   mongod --configsvr --replSet configReplSet --port 37032 --dbpath /Users/kimbyeol/data/configdb_2  --bind_ip localhost
   ```

   그리고 나서 이제 이에 대해서 복제 셋으로 설정하자.
   ```
   mongosh --port 37019
   rsconf = {_id:"configReplSet", members:[{_id:0,host:"localhost:37019"},{_id:1,host:"localhost:37031"},{_id:2,host:"localhost:37032"}]}
   rs.initiate(rsconf)
   ```
  - ```--configsvr``` :mongod를 구성 서버로 사용하겠다는 뜻이다. 이 옵션으로 실행되는 서버에서 클라이언트는 config와 admin 이외의 데이터베이스에 데이터를 쓸 수 없다.
  - config 데이터베이스 : 샤딩된 클러스터 메타데이터를 보유하는 컬렉션, 청크 마이그레이션이나 청크 분할 후처럼 메타데이터가 변경될 때 config 데이터베이스에 데이터를 쓴다.
  - 구성 서버의 일관성을 보장하는 방법
    - writeConcern과 readConcern 모두 **majority**로 설정하여 샤딩된 클러스터 메타데이터가 롤백될 수 없을 때까지 구성 서버 복제 셋에 커밋되지 않는다.
    - writeConcern:
       MongoDB에서 데이터 쓰기 작업을 할 때 writeConcern을 통해 얼마나 강력한 쓰기 보장을 받을지 설정할 수 있습니다.
       **majority**로 설정할 경우, 복제 셋 내의 대부분의 멤버가 쓰기 작업을 확인해야만 쓰기 작업이 완료된 것으로 간주됩니다. 즉, 복제된 여러 서버 중 과반수의 서버가 성공적으로 쓰기를 마쳐야 데이터가 커밋됩니다.
    - readConcern:
      MongoDB에서 데이터 읽기 작업을 할 때 readConcern을 통해 어느 수준의 읽기 일관성을 보장받을지 설정할 수 있습니다.
      **majority**로 설정하면 복제 셋 내에서 과반수의 멤버에게 커밋된 데이터만 읽을 수 있도록 보장합니다. 이를 통해 아직 완전히 커밋되지 않은, 롤백될 가능성이 있는 데이터를 읽는 것을 방지할 수 있습니다.
  - 구성 서버는 클러스터 내 데이터의 목차만 보유하므로 필요한 스토리지 리소스를 최소화해야 한다.
  - 구성 서버 데이터를 자주 백업하자. => 만약 모두 유실된다면 어느 데이터가 어디 위치에 있는지 알기 위해 모든 샤드를 뒤져야 한다.

  ### mongos 프로세스
   ```
   mongos --configdb configReplSet/localhost:37019 --bind_ip localhost --port 37061 --logpath /var/log/mongos.log
   ```
   - 적은 수의 mongos 프로세스를 시작해야 한다. => 구성 서버의 리소스 경합을 유발할 수 있기 때문에
   - 가능한 한 모든 샤드에 가까이 배치해야 한다. => 그래야 여러 샤드에 접근하거나 분산/수집 작업을 수행하는 쿼리의 성능이 향상된다.
   - 고가용성을 보장하기 위해서 mongos 프로세스가 최소 두 개 필요하다.
  ### 복제 셋으로부터 샤딩 추가
  - 만약에 기존 복제셋이 존재하여 이를 샤드로 변환하는 과정을 거쳐야 한다면
    - 먼저 세컨더리를 종료 후에 재시작한다.
      ```mongod --replSet "rs0" --shardsvr --pord 27017 --bind_ip localhost,<멤버의 IP 주소>```
    - 프라이머리에 연갈한 후에 이를 강등한다.
      ```rs.stepDown()```
      - 그 후에 이 프라이머리를 재시작한다.
         ```mongod --replSet "rs0" --shardsvr --pord 27017 --bind_ip localhost,<멤버의 IP 주소>```
    - 이 복제셋들을 샤드로 추가하기 위해 mongos의 admin 테이터베이스에 연결한다.
      ```mongos mongos1.example.net:27017/admin```
      - 그리고 나서 sh.addShard() 메서드를 사용해서 클러스터에 샤드를 추가한다.
  - 샤드를 추가했으면 모든 클라이언트는 복제셋에 직접 연결되어 요청을 보내지 않고 mongos를 통해서 반드시 와야 한다.

 ### 용량 추가
 - 용량을 추가 = 샤드를 추가한다.
 - 책에서 조금 헷갈리게 써놓았는데 결국 정리하면
   - 샤드키를 지정하지 않는 경우 : 샤드끼리는 데이터베이스가 겹쳐서는 안된다.
     - 샤드 A: blog
     - 샤드 B: calendar
     - 샤드 C: mail, tel, music
   - 샤드키를 지정하는 경우 : 데이터베이스는 겹쳐도 되지만 샤드키가 겹쳐서는 안된다.
     - 샤드 A : user의 id가 0부터 100
     - 샤드 B : user의 id가 101부터 200 
### 데이터 샤딩
- 몽고 DB는 데이터를 어떻게 분산할지 알려주기 전에는 자동으로 데이터를 분산하지 않음
- 분산하려는 데이터베이스와 컬렉션명을 명시적으로 알려줘야 한다.
- 그래서 위에 있는 용량 추가 예시가 다소 의문스럽게 느껴졌지만 명시적으로 알려주지 않으려면 위와 같은 용량 추가의 상황이어야 한다고 한다.
- 예를 들어서 데이터 샤딩은 music 데이터베이스의 artist라는 컬렉을 namez키로 샤딩한다고 가정하자.
  - 먼저 music 데이터 베이스의 샤딩을 활성화한다. -> 데이터베이스는 항상 데이터베이스 내 컬렉션보다 먼저 샤딩해야 한다.
  ```
  sh.enableSharding("music")
  ```
  - 데이터베이스 수준에서 샤딩을 활성화하고 나면 sh.shardCollection을 실행해서 컬렉션을 샤딩할 수 있다.
  ```
  sh.shardCollection("music.artists",{"name":1})
  ```
  위 명령은 컬렉션을 청크 단위로 나눈다. 해당 명령은 즉시 끝나지 않고 컬렉션이 크면 최초 분산을 끝내는 데 몇 시간이 걸릴 수도 있다.
- 기존 컬렉션을 샤딩하려면 "name" 필드에 인덱스가 있어야 한다.
- 만약에 샤딩할 컬렉션이 존재하지 않으면 mongos가 자동으로 샤드 키 인덱스를 만든다.
- 샤딩 활성화 명령
  ```
  sh.enableSharding("testDB") // 데이터베이스에 샤딩 활성화
  sh.shardCollection("testDB.users", { user_id: 1 }) // 컬렉션과 샤드 키 설정
  ```
  - 상황 1: users 컬렉션이 없는 경우
    - MongoDB는 users 컬렉션을 생성합니다.
    - user_id 필드에 대해 자동으로 인덱스를 생성합니다:
    - 인덱스: { user_id: 1 }
  - 상황 2: users 컬렉션이 이미 존재하는 경우
    - mongos는 user_id에 대한 인덱스가 존재하는지 확인합니다.
    - 인덱스가 없으면 에러를 반환:
      - 해결: 수동으로 인덱스를 생성해야 합니다.
        ```
        db.users.createIndex({ user_id: 1 })
        ```
## 몽고DB는 어떻게 클러스터 데이터를 추적하는가?
- 각 mongos는 샤드 키가 주어지면, 도큐먼트를 어디서 찾아야 하는지 항상 알아야 하기 때문에 청크 단위로 나눈다.
- 하나의 청크는 항상 하나의 샤드에 위치한다.
- 예를 들어 샤드 키가 {"age":1}이라면 하나의 청크는 "age"필드가 3과 17 사이인 모든 도큐먼트
- 쓰기가 발생하면 청크는 뚱뚱해지고 제거가 발생하면 청크는 홀쭉해진다.
- 만약에 많은 쓰기가 발생한다면 청크는 뚱뚱해지며 데이터 분산 지점이 해결되지 않아 다소 곤란해진다. 그렇기 때문에 몽고 DB는 청크가 일정 크기 이상으로 커지면 자동으로 두 개의 작은 청크로 나눈다.
- 청크들끼리는 범위가 겹치지 않는다. -> 너무 당연한 말이지만, 만약에 여러 곳에 있으면 청크 모두를 확인해야 한다.
- 도큐먼트는 반드시 단 하나의 청크에 소속되어져야 하기 때문에 배열 필드를 샤드키로 만들 수 없다.
### 청크 범위
- 새로 샤딩된 컬렉션은 단일 청크로부터 출발, 모든 도큐먼트는 이 청크에 위치하면 min은 음의 무한대, max는 양의 무한대이다.
- 하지만 청크가 커지만 앞서 말한 것과 같이 두개로 쪼개지는데 그 때는 min이상 some value미만, some value이상 ~max로 나뉘지게 된다.
- 여기서 some value는 분할점이라고 한다.
- 샤드키는 복합해서 만들 수 있다. 이를 복합 샤드키라고 한다.
  - 복합 샤드키는 예를 들어 {"username":1, "age":1}을 말하면 두개의 키로 정렬할 때와 동일한 방식으로 작동한다.
  - 만약에 사용자명인 username이 아닌 age로만 검색한다면 mongos는 모든 청크 혹은 대부분의 청크를 확인해야 한다.
  - 샤드키의 후반부에 걸린 범위는 여러 청크를 가로질러 확인한다. -> 인데스와 동일
### 청크 분할
- 클라이언트가 청크에 쓰기를 하면 mongod는 청크의 분할 임계치를 확인한다.
  - 각 샤드 프라이머리 mongod는 청크에 얼마나 많은 데이터가 삽입되었는지 추적하고 특정 임계치에 이르면 청크를 나눠야할지 확인
  - 나뉘어야 한다면 mongod는 구성 서버에서 전역 청크 구성값을 요청
  - 청크 분할을 수행하고 구성 서버에서 메타데이터를 갱신 만약에 구성서버가 작동하지 않으면 메타 데이터를 갱신할 수 없다 그래서 분할을 위해서는 반드시 구성 서버가 정상 작동중이어야 한다. -> 분할을 시도하고 실패하고를 반복 = 분할소동
  - 새 청크 도큐먼트가 구성서버에 생성, 이전 청크의 범위가 수정된다.
- 분할 임계치에 이르면 mongod는 최상위 청크(가장 많은 도큐먼트를 보유하고 있는 청크)를 이동하도록 밸런서에 요청을 보낸다. 그렇지 않으면 청크가 샤드에 남는다.
  - 샤드의 프라이머리가 최상위 청크를 이동하도록 요청하고 다른 청크는 수동으로 이동하지 않는 한 샤드에 남는다.
  - 샤드키가 단조롭게 증가하는 키를 사용하는 경우 샤드가 과부하 상태가 되는 것을 방지하기 위함
  - 단조롭게 증가하는 샤드 키란:예: 시간 기반 timestamp, 자동 증가 id 등 데이터가 항상 한 방향으로만 커지는 경우를 말합니다. 단조 증가 키를 사용하면 데이터가 특정 샤드에 몰리는 문제가 발생할 수 있습니다.
- 여기서 밸런서는 몽고DB 3.4이후 버전부터 구성 서버 복제셋의 프라이머리 멤버에 백그라운드 프로세스로 작동한다.
- 청크가 크지만 적합한 분할점을 찾지 못할 수도 있다. 샤드키가 같은 도큐먼트들은 같은 청크에 있어야 하기 때문이다. 따라서 샤드 키 값이 변경되는 도큐먼트를 기준으로 분할될 수도 있다.
  - 예를 들어서 age가 13인 도큐먼트들 , 14인 도큐먼트들 이들이 모두 각자의 청크가 된다.
## 밸런서
- "주기적으로 샤드 간의 불균형을 체크하고 청크를 이동"하는 역할은 밸런서(Balancer)가 담당한다. 하지만 이를 수행하기 위해 필요한 데이터를 제공하거나 관리하는 역할은 샤드의 프라이머리(Primary)와 몽고DB의 컨트롤러 역할을 하는 Config 서버가 협력하여 이루어진다.
- 앞서 말했지만  몽고DB 3.4이후 버전부터 구성 서버 복제셋의 프라이머리 멤버에 백그라운드 프로세스로 작동한다.또한 샤드의 청크 수가 특정 마이그레이션 임계치에 이를 때만 활성화
- 임계치에 이르면 벨런서는 청크를 옮긴다. 옮기기 전에 분할해야 하는지도 물어본다.
- 클러스터는 데이터가 옮겨간다는 사실을 몰라도 된다. 이동 완료 전까지 이전 청크로 전달된다. 갱신된 후에는 이전 위치에 접근을 시도하면 mongos 프로세스가 오류를 발생시키고 mongos가 그 로그를 통해서 구성 서버에서 데이터의 새로운 위치를 파악하고
  청크 테이블을 갱신하고 요청을 다시 시도한다.
## 콜레이션 
- 데이터베이스에서 문자열 데이터를 정렬하고 비교하는 방식을 정의하는 규칙
- 주로 대소문자 구분, 문자 간의 비교, 언어별 정렬 규칙 등을 설정할 때 사용
- 기본적으로 콜레이션인 컬렉션을 샤딩하는 것도 가능하다고 한다!
- 이를 위한 두 가지 요구사항
  - 컬렉션에는 접두사가 샤드키인 인덱스가 있어야 한다. = 복합키인 경우 첫번째 필드를 말하는 것이다.
  - 인덱스에는 {locale : "simple"} 콜레이션이 있어야 한다.
## 스트림 변경
- 사용하는 애플리케이션이 데이터베이스 내 데이터의 실시간 변경 사항 추적
- 책에 있는 내용이 정확히 이해되지 않아서 chatgpt에게 요청
- 스트림 변경(Change Streams)은 MongoDB에서 제공하는 기능으로, 데이터베이스 내 데이터의 실시간 변경 사항을 추적할 수 있도록 합니다. 즉, 데이터베이스에서 문서(Document)가 추가, 수정, 삭제될 때 이를 실시간으로 감지하여 애플리케이션에서 처리할 수 있는 방식으로 제공하는 기능입니다.
- 이 기능은 비동기 방식의 이벤트 처리와 연계하여 사용되며, 데이터 변경 사항을 이벤트 스트림 형태로 전달합니다.
  - 구체적인 동작 방식
    - 이벤트 스트림 생성: MongoDB의 watch() 메서드를 사용하여 특정 컬렉션, 데이터베이스, 또는 클러스터 전체에서 발생하는 변경 사항을 추적.
    - 변경 사항 감지: 변경 이벤트(Insert, Update, Delete)가 발생하면 MongoDB가 해당 변경 사항을 스트림 형태로 전달.
    - 애플리케이션 처리: 스트림 데이터를 받아 애플리케이션에서 처리하거나 다른 시스템과 연계. 
  - 예를 들어, 변경 사항을 로그로 저장하거나 실시간 UI 갱신에 활용.
    - 특정 컬렉션에서 데이터 변경 사항 추적:
      ```
      const { MongoClient } = require('mongodb');
      async function watchChangeStream() {
      const client = new MongoClient('mongodb://localhost:27017');
      await client.connect();
      const db = client.db('myDatabase');
      const collection = db.collection('myCollection');
      // Change Stream 생성
      const changeStream = collection.watch();
      // 변경 사항 추적
      changeStream.on('change', (change) => {
         console.log('Change detected:', change);
       });
      }
      watchChangeStream();
      ```
      - 출력 결과
        - MongoDB 컬렉션에서 문서를 추가했을 때:
          ```
          {
          "operationType": "insert",
           "fullDocument": { "_id": 1, "name": "John Doe", "age": 30 },
          "ns": { "db": "myDatabase", "coll": "myCollection" },
         "documentKey": { "_id": 1 }
         }
        ```
      - 문서가 수정되었을 때:
        ```
         {
         "operationType": "update",
         "updateDescription": { "updatedFields": { "age": 31 }, "removedFields": [] },
         "ns": { "db": "myDatabase", "coll": "myCollection" },
        "documentKey": { "_id": 1 }
         }
        ```
     - 문서가 삭제되었을 때:
       ```
        {
        "operationType": "delete",
       "ns": { "db": "myDatabase", "coll": "myCollection" },
        "documentKey": { "_id": 1 }
        }
       ```
- 사용 사례
  - 실시간 알림 시스템: 데이터베이스에서 변경 사항이 발생할 때 사용자에게 실시간 알림 제공.
    예: 주문 상태가 변경되면 고객에게 알림 전송.
  - 실시간 대시보드 업데이트:애플리케이션에서 데이터베이스의 변경 사항에 따라 UI를 실시간으로 갱신.
    예: 주식 가격, 사용자 활동 로그 등.
  - 이벤트 기반 처리:데이터 변경 사항을 Kafka, RabbitMQ 등과 연계하여 다른 시스템으로 전달.
    예: 새 사용자 등록 시 외부 시스템에 이벤트 전달.
  - 데이터 동기화: 서로 다른 데이터베이스 간 실시간 데이터 복제나 동기화.
    예: MongoDB와 Elasticsearch 간 데이터 동기화.
- 주의사항
  - 성능:변경 사항 추적은 추가적인 리소스를 소모하므로, 대규모 트래픽이 발생하는 경우 주의해야 합니다.
  - TTL(Time-to-Live):Change Stream은 Oplog(Operations Log)를 기반으로 작동하며, Oplog의 데이터 보존 기간에 따라 변경 사항을 추적할 수 있는 기간이 제한됩니다.
  - MongoDB 버전: Change Streams는 MongoDB 3.6 이상에서 지원됩니다.
 

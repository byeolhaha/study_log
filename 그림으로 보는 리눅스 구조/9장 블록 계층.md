# 블록 계층
- 블록 계층 : 블록장치(저장장치)의 성능을 향상시키기 위한 커널 기능
앞에서 배운 내용들을 일단 조금 정리해본다.
- 파일 시스템 : 사용자가 데이터에 접근하는 최상위 계층, 파일이나 디렉터리를 관리하고 사용자의 요청을 디바이스 파일로 전달한다.
- 디바이스 파일 : 물리적인 장치(하드디스크..)와 파일 시스템 간의 인터페이스, 파일 시스템이 디바이스에 직접 접근할 수 있도록 파일 시스템의 요청을 디바이스 드리이버로 전달한다.
- 디바이스 드라이버 : 블록 계층에서 받은 요청을 실제 하드웨어에서 치리한다. 하드웨어의 동작을 제어하고, 데이터를 주고 받으며, 운영체제에 결과를 반환한다. 진짜 말 그대로 드라이버로 운영체제와 하드웨어 간의 중재자의 역할
## 하드디스크 특징
- 하드디스크 : 데이터를 자기 정보로 표현해서 플래터라고 불리는 자기 디스크에 기록
- 섹터 : 데이터는 바이트 단위가 아닌 512B 또는 4KiB의 섹터 단위로 읽고 쓴다.
- 자기 헤드 : 저장된 데이터를 읽고 쓴다.
- 스윙암 : 반지름 방향으로 이동하기 위한
- 스윙암과 플레터 회전으로 인한 기계적 처리에 의해서 느리다.
- 각종 파일 시스템은 각 파일 데이터를 가급적 연속적 영역에 배치한다. 
## 블록 계층의 기본 기능
하드디스크의 특징을 의식한 블록 계층의 기본 기능들
- 입출력 스케줄러 : 연속된 섹터의 입출력을 하나의 합치거나 혹은 정렬한다.
  - 합치기 : 연속된 섹터의 입출력 요청을 하나로 합친다.
  - 정렬 : 연속되지 않은 섹터의 입출력 요청을 섹터 번호 순서로 재정렬
- 미리 읽기 : 공간적 지역성에 따라 주변에 읽을 것들을 미리 메모리에 캐시해 두는 것

## 블록 장치의 성능 지표와 측정 방법
- 스루풋 : 몇 시간에 얼마만큼의 데이터 전송
- 레이턴시 : 입출력 1회당 걸린 시간
- IOPS : 초당 처리 가능한 입출력 횟수

## 성능 측정 도구 fio
- 파일 시스템 및 저장 장치의 성능을 측정하고, 다양한 I/O 작업을 시뮬레이션할 수 있는 강력한 성능 측정 도구
- fio는 특히 디스크나 SSD의 성능을 테스트하고, 다양한 입출력 패턴을 통해 읽기, 쓰기, 랜덤 액세스와 같은 다양한 시나리오에서의 성능을 평가하는 데 널리 사용

### 명령어 정리
- ```--name=<job_name>```
작업(job)의 이름을 지정합니다. 동일한 설정으로 여러 작업을 정의할 수 있습니다.

- ```--rw=<readwrite_type>```
I/O 작업의 종류를 정의합니다.
주요 옵션:
read: 순차 읽기
write: 순차 쓰기
randread: 랜덤 읽기
randwrite: 랜덤 쓰기
rw: 순차 읽기/쓰기 혼합
randrw: 랜덤 읽기/쓰기 혼합

- ```--bs=<block_size>```
I/O 블록 크기를 정의합니다. 기본값은 4KB이며, 일반적으로 4KB, 8KB, 16KB 등의 블록 크기로 테스트합니다.
예: --bs=4k는 4KB 블록 크기로 테스트합니다.

- ```--size=<file_size>```
테스트 파일의 크기를 정의합니다. 성능 테스트를 위해 얼마나 많은 데이터를 다룰지를 설정할 수 있습니다.
예: --size=1G는 1GB 크기의 파일을 대상으로 테스트를 진행합니다.

- ```--numjobs=<n>```
테스트할 동시 작업의 수를 지정합니다. 예를 들어, --numjobs=4는 4개의 작업을 동시에 실행하여 성능을 측정합니다.

- ```--runtime=<time>```
테스트의 실행 시간을 설정합니다. 예를 들어, --runtime=30은 30초 동안 테스트를 실행합니다.

- ```--iodepth=<depth>```
I/O 큐의 깊이를 설정합니다. 이 옵션은 비동기 I/O 작업에서 얼마나 많은 요청을 동시에 큐에 넣을지를 결정합니다. 높은 값일수록 더 많은 요청을 병렬로 처리할 수 있습니다.

- ```--ioengine=<engine_type>```
I/O 작업을 처리할 엔진을 설정합니다. fio는 여러 엔진을 지원합니다.
주요 엔진:
sync: 동기식 I/O
libaio: 비동기식 I/O
mmap: 메모리 맵핑을 사용한 I/O
posixaio: POSIX 비동기 I/O

- ```--direct=<value>```
1로 설정하면 캐시를 사용하지 않고 디스크로 바로 접근하는 I/O 테스트를 수행합니다. 0은 시스템 캐시를 사용합니다.
예: --direct=1

- ```--output=<file_name>```
테스트 결과를 파일로 저장합니다.
예: --output=fio_results.txt

- ```--group_reporting```
여러 작업(job)을 동시에 실행할 때, 결과를 그룹화하여 보고합니다.

- ```--filename=<file_name>```
테스트할 파일 또는 장치를 지정합니다. 예를 들어, /dev/sda와 같은 저장 장치나 특정 파일을 지정할 수 있습니다.
예: --filename=/dev/nvme0n1

## 기술 혁신에 따른 블록 계층의 변화

### 책 읽으면서 이해 안되었던 구절
>병렬도가 낮은 무효화 쪽이 레이턴시가 짧은 편이고 병렬도가 높아지면 유효한 편이 짧아지는 결과가 나왔습니다.
이는 NVMe SSD와 같은 고속 저장 장치는 입출력 요청을 일단 모아두는 입출력 스케줄러의 구조에서 발생하는 처리 지연 비용이 하드 디스크에 비해 상대적으로 높기 때문입니다.
ChatGPT 답변
1. NVMe SSD는 기본적으로 고속으로 입출력을 처리할 수 있고, 많은 I/O 요청을 동시에 처리할 수 있는 능력이 뛰어납니다. 이를 **병렬 처리(Parallelism)**이라고 합니다. NVMe SSD는 이미 자체적으로 병렬 처리를 잘 하기 때문에, 운영 체제의 입출력 스케줄러가 추가로 처리할 필요가 적습니다.

2. 입출력 스케줄러는 기본적으로 여러 개의 입출력 요청을 효율적으로 처리하기 위해 요청을 모아서 재배열하거나 그룹화하는 역할을 합니다. 이 스케줄러는 특히 하드 디스크 드라이브(HDD)에서 중요한 역할을 합니다. 하지만 NVMe SSD는 빠른 입출력 성능을 제공하기 때문에, 스케줄러가 개입할 필요가 줄어들거나 오히려 성능을 방해할 수 있습니다.

3. 병렬도가 낮은 경우: 만약 처리할 입출력 요청의 개수가 적다면, 스케줄러를 끄는 것이 더 효율적입니다(스케줄러 무효화). 이 경우, 입출력 요청을 모아서 처리할 필요가 없기 때문에, 곧바로 요청을 NVMe SSD가 처리할 수 있어서 레이턴시가 짧아집니다. 스케줄러가 개입하지 않으므로, 스케줄링으로 인한 처리 지연이 발생하지 않는 것이죠.

4. 병렬도가 높은 경우: 입출력 요청이 매우 많을 때는, 스케줄러를 켜는 것이 더 유리해질 수 있습니다(스케줄러 유효화). 왜냐하면 스케줄러가 많은 요청을 잘 관리해 효율적으로 배치할 수 있기 때문입니다. NVMe SSD는 병렬 처리가 강점이지만, 요청이 많으면 스케줄러의 추가적인 최적화가 성능을 더 개선할 수 있습니다. 이때는 스케줄러가 입출력 요청을 적절히 재배열하여 SSD의 병렬 처리 성능을 극대화하는 것이 가능합니다.

### 책 읽으면서 생긴 의문점
>mysql에서 innoDB는 버퍼풀에 데이터 페이지들을 저장하잖아 이것도 블록계층의 미리 읽기에 해당하는 건가?
ChatGPT 답변
1. InnoDB 버퍼 풀:
InnoDB 버퍼 풀은 MySQL InnoDB 스토리지 엔진에서 사용하는 메모리 영역으로, 자주 사용되거나 앞으로 필요할 가능성이 있는 **데이터 페이지(테이블, 인덱스 등의 데이터)**를 메모리에 저장합니다.
InnoDB는 디스크에서 데이터를 가져오는 대신 메모리에서 빠르게 데이터를 처리할 수 있도록 데이터를 캐시하는 역할을 합니다.
InnoDB는 또한 **미리 읽기(read-ahead)**와 LRU 알고리즘 등을 활용해, 쿼리 성능을 최적화하고 필요한 데이터를 미리 버퍼에 로드하여 디스크 I/O를 줄입니다.
2. 블록 계층의 미리 읽기(Read-ahead):
블록 계층의 미리 읽기는 운영 체제의 I/O 서브시스템에서 사용하는 전략으로, 데이터 접근 패턴을 분석해 앞으로 필요할 것으로 예상되는 블록을 미리 디스크에서 읽어 메모리나 디스크 캐시에 저장하는 작업입니다.
파일 시스템이나 블록 계층은 디스크 I/O 비용을 줄이고 성능을 향상시키기 위해 사용자가 요청하기 전에 데이터를 미리 읽습니다.
이는 하드웨어와 운영 체제 사이의 계층에서 일어나며, 블록 단위로 데이터를 처리합니다.
둘의 공통점과 차이점:
공통점: InnoDB 버퍼 풀과 블록 계층의 미리 읽기 모두 성능 최적화를 목적으로 하며, 앞으로 필요할 데이터를 미리 메모리에 로드해 디스크 I/O를 줄이는 전략입니다.
차이점:
InnoDB 버퍼 풀은 MySQL 데이터베이스 레벨에서 동작하는 캐싱 메커니즘으로, DB의 데이터 페이지(테이블, 인덱스 등)를 관리합니다.
블록 계층의 미리 읽기는 운영 체제의 스토리지 계층에서 동작하며, 파일 시스템이나 블록 장치 레벨에서 블록 단위로 데이터를 관리합니다.

# 2장 카프카 설치하기
배우는 내용
- 아파치 주키퍼 설치(브로커의 메타 데이터를 저장)하는 방법
- 아파치 카프카를 설치하기 위한 기본적인 설정 옵션
- 브러커를 실행하는 데 적합한 하드웨어를 선택하는 기준
- 여러 개의 카프카 브로커를 하나의 클러스터로 구성하는 방법
- 카프카를 프로덕션 환경에서 사용할 때 알아 두어야 할 것들
## 2.1 환경 설정
- 운영체제 선택하기
  대체로 리눅스 환경을 권장
- 자바 설치하기
  주키퍼와 카프카 모두 OpenJDK 기반 자바 구현체에서 원활히 작동함
  최신 버전을 다운받을 것을 권장
- 주키퍼 설치하기
  >주키퍼란
  카프카 클러스터의 메타데이터와 컨수머 클라이언트에 대한 정보를 저장
  설정 정보 관리, 이름 부여, 분산 동기화, 그룹 서비스를 제공하는 중앙화된 서비스
  - 독립 실행 서버
  - 주키퍼 앙상블
    - 주키퍼는 고가용성을 보장하기 위해서 앙상블이라 불리는 클러스터 단위로 작동 = 주키퍼도 단일 장애 지점을 피하기 위해서 여러 대의 서버로 운영
    - 이 앙상블은 홀수 개의 서버를 가지도록 권장되며, 안의 서버들이 과반수이상 작동해야 하기 때문이다.
      또한 5개의 노드 크기를 고려하라고 한다. 그 이유는 하나의 서버의 설정을 변경하면 중지하고 다시 시작해야 하는데 2대 이상의 노드 정지를 받아낼 수 없다면 위험이 따르기 때문이라고 한다.
      그러나 9대 이상의 서버를 유지하는 것도 권장하지 않는다고 한다. 그래서 5,7대를 유지하고 옵저버 서버를 차라리 추가하라고 권장한다.
      나는 이 부분을 읽으면서 몇가지 궁금한 점이 발생했고 그리고 몽고 디비의 복제셋과 비슷하게 관리되어짐을 깨달았다.
      - 왜 9대 이상일 때 성능 저하가 발생할까?
       chatGPT에 따르면
       ```
        카프카는 리더 선출과 데이터 일관성 유지를 위해 합의 프로토콜(예: ZooKeeper)을 사용합니다. 노드 수가 많아질수록 합의 과정에서 모든 노드가 동일한 상태를 유지하려고 서로 간의 메시지를 주고받는 작업이 증가합니다. 이로 인해 다음과 같은 성능 저하가 발생할 수 있습니다:
        - 합의 지연: 노드가 많아질수록 모든 노드 간의 합의에 필요한 시간이 늘어납니다. 특히 장애가 발생했을 때, 새로운 리더를 선출하거나 복구하는 과정에서 지연이 더 커질 수 있습니다.
        - 통신 오버헤드 증가: 노드가 9대를 넘어서면, 각 노드가 서로 데이터를 동기화하고 일관성을 유지하기 위해 통신하는 횟수가 급격히 증가합니다. 이에 따라 네트워크 및 처리 오버헤드가 늘어나 성능이 떨어질 수 있습니다.
        따라서 카프카는 노드 수를 9대 이하로 유지하도록 권장하며, 필요시 클러스터를 분리해 여러 클러스터로 운영하는 방식을 추천하는 경우가 많습니다.
       ```
      - 왜 5대와 7대일까? 2개 이상의 노드 정지를 받아낼 수 없으면 왜 위험이 따르는가?
       ```
       1. 왜 5대나 7대를 유지하라는가?
       홀수 노드 사용의 장점: 카프카와 같은 분산 시스템은 과반수 합의에 따라 리더 선출과 클러스터 상태를 유지합니다. 홀수 개의 노드를 사용하면 과반수 결정이 명확해 합의 과정에서 효율적입니다.
       안정성과 성능의 균형:
       - 5대: 2대까지 장애를 허용할 수 있으므로 안정적이면서도 운영 비용을 최소화합니다.
       - 7대: 3대까지 장애 허용이 가능하여 더 높은 안정성을 제공합니다.
       - 장애 내성: 홀수 개의 노드를 사용함으로써 재시작이나 장애가 발생할 때도 과반수를 쉽게 유지할 수 있습니다. 예를 들어, 5대에서 2대가 중지돼도 과반수를 유지하지만, 6대처럼 짝수 개를 사용하면 3대가 중지되었을 때 과반수를 유지할 수 없어 더 불안정해집니다.
       2. 9대 이상 사용을 권장하지 않는 이유
       합의 프로토콜 성능 저하: 9대 이상의 노드가 있으면, 카프카의 리더 선출이나 데이터 일관성을 맞추기 위한 합의 과정에서 네트워크 통신과 검증 작업이 급격히 늘어납니다.
       - 오버헤드 증가: 모든 노드가 서로 상태를 확인하고 일관성을 유지하려고 할 때, 네트워크와 리소스 오버헤드가 커지며 성능 저하가 발생할 수 있습니다. 특히 장애가 발생했을 때 새로운 리더를 빠르게 선출하기 어려워집니다.
       - 효율적 관리의 한계: 9대 이상은 추가적인 관리와 네트워크 비용이 발생하며, 안정성 향상보다 성능 저하 위험이 커져 클러스터 관리가 어려워집니다.
      ```
## 2.2 카프카 설치하기
- 나는 도커 컴포즈 통해서 설치했다.
```yml
version: '3.8'

volumes:
  Kafka00:
    driver: local
  Kafka01:
    driver: local
  Kafka02:
    driver: local

networks:
  kafka_network:
    driver: bridge

services:
  # Zookeeper 3개 (앙상블)
  zookeeper-0:
    image: bitnami/zookeeper:3.9.2
    container_name: zookeeper-0
    ports:
      - 2181:2181
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_SERVERS: zookeeper-0:2888:3888,zookeeper-1:2888:3888,zookeeper-2:2888:3888
      ALLOW_ANONYMOUS_LOGIN: yes
    networks:
      - kafka_network

  zookeeper-1:
    image: bitnami/zookeeper:3.9.2
    container_name: zookeeper-1
    ports:
      - 2182:2181
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SERVER_ID: 2
      ZOOKEEPER_SERVERS: zookeeper-0:2888:3888,zookeeper-1:2888:3888,zookeeper-2:2888:3888
      ALLOW_ANONYMOUS_LOGIN: yes
    networks:
      - kafka_network

  zookeeper-2:
    image: bitnami/zookeeper:3.9.2
    container_name: zookeeper-2
    ports:
      - 2183:2181
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SERVER_ID: 3
      ZOOKEEPER_SERVERS: zookeeper-0:2888:3888,zookeeper-1:2888:3888,zookeeper-2:2888:3888
      ALLOW_ANONYMOUS_LOGIN: yes
    networks:
      - kafka_network

  # Kafka 3개 브로커
  Kafka00Service:
    image: bitnami/kafka:3.7.0
    container_name: Kafka00Container
    ports:
      - '10000:9094'
    environment:
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_BROKER_ID=0
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper-0:2181,zookeeper-1:2181,zookeeper-2:2181
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,EXTERNAL://:9094
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://Kafka00Service:9092,EXTERNAL://127.0.0.1:10000
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_CFG_CLUSTER_ID=5p3DaHv8SBqPAbW7L98j0w
    networks:
      - kafka_network
    volumes:
      - Kafka00:/bitnami/kafka/data

  Kafka01Service:
    image: bitnami/kafka:3.7.0
    container_name: Kafka01Container
    ports:
      - '10001:9094'
    environment:
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_BROKER_ID=1
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper-0:2181,zookeeper-1:2181,zookeeper-2:2181
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,EXTERNAL://:9094
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://Kafka01Service:9092,EXTERNAL://127.0.0.1:10001
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_CFG_CLUSTER_ID=5p3DaHv8SBqPAbW7L98j0w
    networks:
      - kafka_network
    volumes:
      - Kafka01:/bitnami/kafka/data

  Kafka02Service:
    image: bitnami/kafka:3.7.0
    container_name: Kafka02Container
    ports:
      - '10002:9094'
    environment:
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_BROKER_ID=2
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper-0:2181,zookeeper-1:2181,zookeeper-2:2181
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,EXTERNAL://:9094
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://Kafka02Service:9092,EXTERNAL://127.0.0.1:10002
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_CFG_CLUSTER_ID=5p3DaHv8SBqPAbW7L98j0w
    networks:
      - kafka_network
    volumes:
      - Kafka02:/bitnami/kafka/data

  # Kafka Web UI
  KafkaWebUiService:
    image: provectuslabs/kafka-ui:latest
    container_name: KafkaWebUiContainer
    ports:
      - '8080:8080'
    environment:
      - KAFKA_CLUSTERS_0_NAME=Local-Kafka-Cluster
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=Kafka00Service:9092,Kafka01Service:9092,Kafka02Service:9092
      - DYNAMIC_CONFIG_ENABLED=true
    networks:
      - kafka_network


```
- 3개의 주키퍼 앙상블을 만들었다.
- 주키퍼 앙상블 설정:
  - ZOOKEEPER_SERVER_ID: 각 노드에 고유한 ID를 설정 (1, 2, 3).
  - ZOOKEEPER_SERVERS: 전체 주키퍼 노드의 목록을 설정.
  - 2888:3888 포트는 주키퍼 노드 간 통신용 포트입니다.
- 각 노드의 포트:
  - zookeeper-0: 클라이언트 포트 2181.
  - zookeeper-1: 클라이언트 포트 2182.
  - zookeeper-2: 클라이언트 포트 2183.
- Kafka 설정:
  - KAFKA_CFG_ZOOKEEPER_CONNECT: 앙상블의 모든 주키퍼 노드 주소를 설정.
- Kafka-UI:Kafka 브로커 kafka-0를 사용하여 모니터링.
- 주키퍼 설정에 대한 각 설명
  1. image: bitnami/zookeeper:3.9.2
     Bitnami에서 제공하는 Zookeeper 3.9.2 버전의 Docker 이미지를 사용합니다.
  2. container_name: zookeeper-2 컨테이너의 이름을 zookeeper-2로 지정합니다. 이를 통해 관리 및 참조 시 명확하게 구분할 수 있습니다.
  3. ports: - 2183:2181
     - 2183: 호스트 머신(로컬 머신)의 포트입니다.
     - 2181: 주키퍼의 클라이언트 포트입니다.
     - 의미: 로컬 머신의 2183 포트를 zookeeper-2 컨테이너의 2181 포트에 매핑합니다.따라서 클라이언트는 localhost:2183을 통해 이 노드에 접근할 수 있습니다.
  4. environment 환경변수
     주키퍼 컨테이너가 실행될 때 필요한 설정들을 환경 변수로 제공합니다.
     - ZOOKEEPER_CLIENT_PORT: 2181 클라이언트가 이 노드에 접속하기 위한 포트 번호입니다. 기본값은 2181입니다.
     - ZOOKEEPER_SERVER_ID: 3 이 주키퍼 노드의 고유 ID입니다. 주키퍼 앙상블에서 각 노드는 ID를 통해 자신을 식별합니다. ID는 1부터 순차적으로 할당됩니다.
     - ZOOKEEPER_SERVERS 앙상블에 참여하는 모든 주키퍼 노드의 정보를 명시합니다.
       - 각 항목의 의미:
         - zookeeper-0:2888:3888
         - zookeeper-0: 노드 이름.
         - 2888: 노드 간 데이터 동기화 포트.
         - 3888: 리더 선출을 위한 투표 포트.
         - zookeeper-1:2888:3888: 두 번째 노드.
         - zookeeper-2:2888:3888: 세 번째 노드.
         - 요약: 주키퍼 노드들은 서로 이 포트들을 통해 통신하며 앙상블의 상태를 유지합니다.
     - ALLOW_ANONYMOUS_LOGIN: yes 익명 사용자의 접근을 허용합니다.테스트용으로 주로 사용되며, 프로덕션에서는 보안을 위해 설정을 변경해야 합니다.
- 토픽 생성
  ```
  docker exec -it Kafka00Container kafka-topics.sh \
  --create \
  --bootstrap-server Kafka00Service:9092 \
  --replication-factor 2 \
  --partitions 1 \
  --topic test-topic


  ```
- 메시지 생성
  ```
  docker exec -it Kafka00Container kafka-console-producer.sh \
  --bootstrap-server Kafka00Service:9092 \
  --topic test-topic
  ```
- 메시지 읽기
  ```
   docker exec -it Kafka01Container kafka-console-consumer.sh \
  --bootstrap-server Kafka01Service:9092 \
  --topic test-topic \
  --from-beginning
  ```
![image](https://github.com/user-attachments/assets/d0a017e5-d168-41f4-bfc2-6f0b7819b75c)

- 위 버전은 주키퍼를 사용하는 버전이며 버전이 업그레이드 되면서 메타 정보들을 카프카 자체에서 관리할 수 있도록 바뀌었다고 한다.
  - Zookeeper 모드: Kafka 클러스터의 메타데이터를 Zookeeper가 관리한다.
  - KRaft 모드: Kafka 자체가 메타데이터를 관리합니다. Zookeeper가 필요하지 않다. **Kafka 2.8.0+**에서 도입되었고, Kafka 3.x부터는 추천되는 방식이다.
  - KRaft모드는 아래와 같다.
```
networks:
  kafka_network:

volumes:
  Kafka00:
  Kafka01:
  Kafka02:

services:
  ### Kafka00
  kafka00:
    image: bitnami/kafka:3.7.0
    restart: unless-stopped
    container_name: kafka00
    ports:
      - '10000:9094'
    environment:
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      # KRaft settings
      - KAFKA_CFG_BROKER_ID=0
      - KAFKA_CFG_NODE_ID=0
      - KAFKA_KRAFT_CLUSTER_ID=HsDBs9l6UUmQq7Y5E6bNlw
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka00:9093,1@kafka01:9093,2@kafka02:9093
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      # Listeners
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:9094
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka00:9092,EXTERNAL://127.0.0.1:10000
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      # Clustering
      - KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR=3
      - KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=3
      - KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR=2
    networks:
      - kafka_network
    volumes:
      - "Kafka00:/bitnami/kafka"
  ### Kafka01
  kafka01:
    image: bitnami/kafka:3.7.0
    restart: unless-stopped
    container_name: kafka01
    ports:
      - '10001:9094'
    environment:
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      # KRaft settings
      - KAFKA_CFG_BROKER_ID=1
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_KRAFT_CLUSTER_ID=HsDBs9l6UUmQq7Y5E6bNlw
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka00:9093,1@kafka01:9093,2@kafka02:9093
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      # Listeners
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:9094
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka01:9092,EXTERNAL://127.0.0.1:10001
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      # Clustering
      - KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR=3
      - KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=3
      - KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR=2
    networks:
      - kafka_network
    volumes:
      - "Kafka01:/bitnami/kafka"
  ## Kafka02
  kafka02:
    image: bitnami/kafka:3.7.0
    restart: unless-stopped
    container_name: kafka02
    ports:
      - '10002:9094'
    environment:
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      # KRaft settings
      - KAFKA_CFG_BROKER_ID=2
      - KAFKA_CFG_NODE_ID=2
      - KAFKA_KRAFT_CLUSTER_ID=HsDBs9l6UUmQq7Y5E6bNlw
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka00:9093,1@kafka01:9093,2@kafka02:9093
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      # Listeners
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:9094
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka02:9092,EXTERNAL://127.0.0.1:10002
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      # Clustering
      - KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR=3
      - KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=3
      - KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR=2
    networks:
      - kafka_network
    volumes:
      - "Kafka02:/bitnami/kafka"

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    restart: unless-stopped
    container_name: kafka-ui
    ports:
      - '8080:8080'
    environment:
      - KAFKA_CLUSTERS_0_NAME=Local-Kraft-Cluster
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka00:9092,kafka01:9092,kafka02:9092
      - DYNAMIC_CONFIG_ENABLED=true
      - KAFKA_CLUSTERS_0_AUDIT_TOPICAUDITENABLED=true
      - KAFKA_CLUSTERS_0_AUDIT_CONSOLEAUDITENABLED=true
      #- KAFKA_CLUSTERS_0_METRICS_PORT=9999
    depends_on:
      - kafka00
      - kafka01
      - kafka02
    networks:
      - kafka_network
  ```

## 2.3 브로커 설정하기
### 2.3.1 핵심 브로커 매개변수
```
  kafka-0:
    image: bitnami/kafka:3.7.0
    container_name: kafka-0
    ports:
      - 9094:9094
    depends_on:
      - zookeeper-0
      - zookeeper-1
      - zookeeper-2
    environment:
      ALLOW_PLAINTEXT_LISTENER: yes
      KAFKA_ENABLE_KRAFT: no
      KAFKA_CFG_ZOOKEEPER_CONNECT: zookeeper-0:2181,zookeeper-1:2181,zookeeper-2:2181
      KAFKA_CFG_LISTENERS: PLAINTEXT://:9092,EXTERNAL://:9094
      KAFKA_CFG_ADVERTISED_LISTENERS: PLAINTEXT://kafka-0:9092,EXTERNAL://localhost:9094
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT,PLAINTEXT:PLAINTEXT
```
- 일단 나는 책과 다르게 도커 컴포즈를 통해서 만들었기 때문에 이를 기준으로 정리하려고 한다. 하지만 이 내용은 브로커를 설치할 때 설정해야 하는 값이며 양식만 조금 다른거 같다.
- 브로커 ID
  - KAFKA_CFG_BROKER_ID를 이용해서 명시적으로 브로커 ID를 설정할 수 있으며 생략하는 경우 0부터 순차적으로 준다고 한다.
- 리스너
  > **Kafka에서 리스너(listener)** 는 클라이언트(프로듀서, 컨슈머) 또는 브로커(다른 Kafka 브로커 및 컨트롤러)가 Kafka 브로커와 통신하기 위해 사용하는 네트워크 엔드포인트.
쉽게 말해, **Kafka가 외부와 통신하기 위해 "열어놓은 문"**
  - 구버전은 단순히 포트 설정이지만 새로 도입된 버전에서는 쉼표로 구분된 리스터 이름과 URI 목록
  - 일반적인 보안 프로토콜이 아니라면 반드시 KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP 설정을 잡아주어야 한다.
  - 리스너는 {프로토콜}://{호스트이름}:{포트}의 형태
  - Kraft 모드 설정
    ```
          # Listeners
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:9094
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka01:9092,EXTERNAL://127.0.0.1:10001
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
    ```
    - ALLOW_PLAINTEXT_LISTENER=yes
      - Kafka가 암호화 없이 PLAINTEXT(평문) 리스너를 허용하도록 설정합니다.
      - 보안 설정 없이 Kafka 브로커와 통신할 수 있습니다.
      - 운영 환경에서는 보안상 TLS(SSL) 등을 설정하는 것이 권장되지만, 개발/테스트 환경에서는 편의상 PLAINTEXT를 사용할 수 있습니다.
    - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:9094
      - Kafka 브로커가 어떤 네트워크 인터페이스 및 포트에서 연결을 수락할지 지정하는 설정입니다.
      - PLAINTEXT://:9092 – 내부 브로커 및 클라이언트 통신용 (Kafka 클라이언트가 접속)
      - CONTROLLER://:9093 – 컨트롤러 통신을 위한 포트 (KRaft 모드에서 사용)
      - EXTERNAL://:9094 – 외부에서 Kafka에 접근할 수 있는 외부 클라이언트 통신 포트
      - 각 리스너는 다른 포트에서 서로 다른 목적으로 사용됩니다.
    - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka01:9092,EXTERNAL://127.0.0.1:10001
      - 클라이언트(예: Kafka 프로듀서, 컨슈머)가 브로커에 접근할 때 사용하는 호스트와 포트 정보를 클러스터에 알립니다.
      - PLAINTEXT://kafka01:9092 – 내부 네트워크에서 Kafka 브로커가 클러스터 내에서 사용할 주소
      - EXTERNAL://127.0.0.1:10001 – 외부 클라이언트가 localhost:10001로 Kafka에 접속할 수 있도록 설정
      - advertised(광고) 리스너는 클라이언트가 브로커에 접속할 때 사용해야 하는 호스트와 포트를 정의합니다.
    - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - 각 리스너에서 사용할 보안 프로토콜을 매핑하는 설정입니다.
      - CONTROLLER:PLAINTEXT – 컨트롤러 통신은 평문(PLAINTEXT)으로 수행
      - EXTERNAL:PLAINTEXT – 외부 클라이언트도 평문으로 통신
      - PLAINTEXT:PLAINTEXT – 내부 브로커 및 클라이언트 통신도 평문으로 설정
    - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - Kafka 브로커가 컨트롤러 역할을 수행할 때 사용하는 리스너를 지정합니다.
      - CONTROLLER 리스너(9093 포트)를 통해 Kafka 컨트롤러로서 동작하며, 다른 브로커와 클러스터 메타데이터를 주고받습니다.
    - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - Kafka 브로커 간의 통신(클러스터 내부 통신)에 사용할 리스너를 지정합니다.
      - PLAINTEXT 리스너(9092 포트)를 통해 브로커 간 통신을 수행합니다.
- zookeeper.connect
  - 구버전에 주키퍼가 필요할 때 해당 값을 설정해줬는데 Kraft모드에서는 사라진 설정
- log.dirs
  - 카프카는 모든 메시지를 로그 세그먼트 단위로 묶어서 log.dir 설정에 지정된 디스크 디렉토리에 저장
  - 다수의 디렉토리를 지정하고자 하는 경우 , log.dirs를 사용하자
  - 이 설정을 하지 않는 경우, log.dir가 사용되며 나의 경우 설정을 안해줘서 살펴보니 아래와 같이 기본 설정으로 된 거 같다.
    ![image](https://github.com/user-attachments/assets/a015ffc0-2288-49b4-90e9-cedba8a17130)
  - KAFKA_CFG_LOG_DIRS=/bitnami/kafka/logs
    - 위와 같이 설정 가능하며 쉼표로 구분해서 경로 목록을 만들어도 된다.
    - 1개 이상의 경로가 지정되었을 경우, 브로커는 가장 적은 수의 파티션이 저장된 디렉토리에 새 파티션을 저장한다.
    - 같은 파티션에 속하는 로그 세그먼트는 동일한 경로에 저장된다.
    - 사용된 디스크 용량 기준이 아닌 저장된 파티션 수 기준으로 새 파티션이 저장된 디렉토리 위치를 배정한다!!!!
    - 그래서 다수의 디렉토리에 대해 균등한 양의 데이터가 저장되지 않는다.
- num.recovery.threads.per.data.dir (KAFKA_CFG_NUM_RECOVERY_THREADS_PER_DATA_DIR=4)
  - 카프카는 설정 가능한 스레드 풀을 사용해서 로그 세그먼트를 관리한다.
  - 아래 작업을 수행한다.
    - 브로커가 정상 시작되었을 때 로그 세그먼트 파일을 연다.
    - 장애가 발생하고 다시 시작하면, 각 파티션의 로그 세트먼트 파일을 검사하고 잘못된 부분 삭제
    - 브로커가 종료되었을 때 로그 세그먼트를 정상적으로 닫는다.
  - 기본적으로 하나의 로그 디렉토리에 대해 하나의 스레드만 사용
      ![image](https://github.com/user-attachments/assets/5cbd32f1-0a81-4eaa-84a3-5008eedc8d88)
  - 만약에 하나의 스레드만 사용되고 브로커에 500개의 파티션이 있고 3개의 로그 디렉토리가 있다면 브로커가 언클린 셧다운이 되었을 때
      장애를 복구하기 위해서 하나의 스레드가 직렬적으로 복구를 수행한다. 하지만 예를 들어 4개의 스레드가 배정되어 있다면 이 4개의 스레드가 병렬적으로 복구를 수행할 수 있다.
  - 따라서 로그 디렉토리에 배정된 스레드의 수에 따라 복구 시간이 길어지냐 짧아지냐가 결정되게 되며, 너무 많으면 네트워크 I/O가 많아져 병목이 심해지고 CPU사용량을 급격하게 많아져 오히려 느려질 수 있으니 본인의 서버 사양에 따라 테스트를 진행하여 설정해야 한다.
- auto.create.topics.enalbe (KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE)
  - 기본 설정에는 아래와 같은 상황에서 브로커가 토픽을 자동으로 생성한다. = kafka에서 토픽이 존재하지 않더라도 자동으로 생성하는 기능
    - 프로듀셔가 토픽에 메시지를 쓰기 시작할 때
    - 컨슈머가 프로듀서로부터 메시지를 읽기 시작할 때
    - 클라이언트가 토픽에 대한 메타데이터를 요청할 때
  - 하지만 이는 바람직하지 않다. 어떤 상황인지는 챗지피티를 통해 아래와 같이 정리해본다.
    1. 오타나 잘못된 설정으로 인한 토픽 생성
       - 만약 프로듀서가 event-log 대신 evnt-log라는 잘못된 토픽에 메시지를 보내면 Kafka는 evnt-log라는 토픽을 자동으로 생성합니다.
       - 개발자는 잘못된 토픽이 생성된 것을 인지하지 못하고, 이후 데이터가 잘못된 토픽으로 흘러 들어갑니다. 이로 인해 데이터 유실 및 분석 오류가 발생할 수 있습니다.
    2. 불필요한 토픽 증가
       - 컨슈머나 클라이언트가 잘못된 메타데이터 요청을 보내면 의미 없는 빈 토픽들이 무분별하게 생성됩니다. 시스템 자원이 낭비되고, 관리해야 할 토픽 수가 불필요하게 증가합니다.
    3. 토픽 설정 불일치
       - 자동 생성된 토픽은 기본 설정을 사용하므로, 복제 인수(replication factor)나 파티션 수가 적절하지 않을 수 있습니다. Kafka 클러스터의 데이터 안정성 및 부하 분산에 악영향을 줄 수 있습니다.
- auto.leader.rebalance.enable
  - 모든 토픽의 리더 역할이 하나의 브로커에 집중됨으로써 카프카 클러스터의 균형이 깨지는 수가 있다.
  - 이 설정을 활성화하면 가능한 한 리더 역할이 균등하게 분삼되도록 함
  - 파티션의 분포 상태를 주기적으로 확인하는 백그라운드 스레드가 시작되며 주기는 leader.imbalance.check.interval.seconds 값으로 설정한다.
  - 만약에 전체 파티션 중에 특정 브로커에 리더 역할이 할당된 파티션의 비율이 leader.imbalance.per.broker.percentage에 설정된 값이 넘어가면 파티션의 선호 리더 리밸런싱이 발생한다.
  - 설정은 아래와 같으며 클러스터 안에 여러 개의 브로커가 존재하는 경우 브로커마다 설정해준다.
    - KAFKA_CFG_AUTO_LEADER_REBALANCE_ENABLE=true
    - KAFKA_CFG_LEADER_IMBALANCE_CHECK_INTERVAL_SECONDS=300
    - KAFKA_CFG_LEADER_IMBALANCE_PER_BROKER_PERCENTAGE=10
- delete.topic.enable (KAFKA_CFG_DELETE_TOPIC_ENABLE=true)
  - 클러스터의 토픽을 임의로 삭제하지 못하게끔 막아야할 때가 있을 때 false로 설정
### 2.3.2 토픽별 기본값
- 카프카 브로커 설정은 새로 생성되는 토픽에 적용되는 수많은 설정의 기본값 역시 지정한다.
1. num.partitions
 - 새로운 토픽이 생성될 때 몇 개의 파티션을 갖게 되는지를 결정
 - 주로 자동 토픽 생성이 활성화되어 있을 때 사용된다. 기본값은 1이다.
 - 토픽의 파티션 수는 늘릴 수만 있지 줄일 수는 없다!!!! 만약에 줄일려면 직접 토픽을 생성해야 한다.
 - 왜 줄일 수는 없는가를 지피티에 물어봤다.
   Kafka에서 파티션 수는 늘릴 수만 있고 줄이는 것은 불가능합니다.
   이는 Kafka의 데이터 분산 및 메시지 순서 보장 메커니즘 때문입니다.
   1. 데이터 일관성 문제
      - 파티션을 줄이면 기존 데이터의 일부가 유실되거나 잘못된 순서로 재배치될 위험이 있습니다.
      - Kafka는 파티션 내에서 메시지 순서를 보장합니다.
      - 파티션을 줄이면, 순서가 꼬이거나 메시지가 중복/누락될 수 있기 때문에 안전하지 않습니다.
   2. 리더 선출 문제
      - 각 파티션에는 리더 파티션이 존재하며, 컨슈머는 리더에서 데이터를 읽습니다.
      - 파티션을 줄이면 리더 파티션도 사라지게 되므로, 클러스터 안정성에 영향을 미칩니다.
   3. 해시 기반 파티셔닝
      - Kafka는 해시 기반 파티셔닝을 사용해 메시지를 특정 파티션에 할당합니다.
      - 파티션을 줄이면, 기존 해시 값과 매핑된 파티션이 사라지기 때문에 일관된 해시 기반 분산이 깨집니다.
- 토픽 자동 생성이 비활성화되어 있는 경우 아래와 같이 Kafka CLI를 사용해 직접 생성한다.
  - kafka-topics.sh --create --topic my-topic --bootstrap-server localhost:9092 --partitions 3 --replication-factor 2
  

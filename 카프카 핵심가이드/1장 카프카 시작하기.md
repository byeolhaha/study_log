## 1.1 발행/구독 메시지 전달
- 전송자가 데이터를 보낼 때 데이터를 직접 수신자에게 보내지 않는다는 것
- 대신 전송자는 데이터를 분류해서 보내고 수신자를 이들 구독하고 있다.
- 발행/구독 시스템에서 대게 발행된 메시지를 전달하고 중계해주는 중간 역할 = 브로커
### 1.1.1 초기의 발행/구독 시스템
![image](https://github.com/user-attachments/assets/7654672c-97de-4051-a293-aa06570b3a66)

1. 발행자와 구독자가 직접 연결된 단일 지표 발행자

![image](https://github.com/user-attachments/assets/6e35e10e-bb20-46fe-8bbd-25c1f13793d7)

2. 하지만 단일 지표에서 이제는 이를 분석하는 분석 서버, 활동 모니터링 등과 같은 서버가 추가되면 발행자와 구독자는 직접 연결되어져 있기 때문에 연결을 추적하기 굉장히 힘들다.

![image](https://github.com/user-attachments/assets/c7c79b1c-f154-4d1f-be4d-3dfacf33a7bf)

3. 그래서 중간에 모든 지표 값을 받는 하나의 애플리케이션을 만들고, 이 지표를 필요로 하는 시스템이 질의를 할 수 있도록 만든다.
### 1.1.2 개별 메시지 큐 시스템
하지만 이제 지표가 아닌 로그 메세지에 대해서 비슷한 작업이 추가된다. 
![image](https://github.com/user-attachments/assets/269ed8b6-e760-432a-b610-55ce116e2aa5)
- 그렇다면 위와 같이 증복과 관리 포인트가 늘어난다.
## 1.2 카프카 입문
위와 같은 문제들을 해결하기 위해 고안된 발생/구독 시스템
- 분산 커밋 로그 또는 분산 스트리밍 플랫폼
- 파일 시스템이나 데이터 베이스 커밋 로그는 모든 트랜잭션 기록을 지속상있게 보존함으로써 시스템의 상태를 일관성 있게 복구 = 카프카에 저장된 데이터는 순서를 유지, 지속성 있게 보관, 읽을 수 있다.
- 확장시 성능 향상시키고 실패가 발생하더라도 데이터 사용에는 문제가 없도록 시스템 내에서 분산시켜 저장할 수 있다.
### 1.2.1 메시지와 배치
메시지
- 데이터의 기본 단위, 레코드나 로우와 비슷한
- 키라도 불리우는 메타 데이터를 포함할 수도 있다.
- 키는 특별한 의미가 없고 파티션을 결정하기 위해 사용 ( 혹은 메시지의 중복을 체크하기 위해서도 사용된다.)

배치
- 효율성을 위해서 배치 단위로 저장
- 같은 토픽의 파티션에 쓰여지는 메시지들의 집합
- 메시지가 생길 때마다 쓰는 것은 많은 네트워크상에서의 신호가 발생하므로 오버헤드 따라서 메시지를 배치 단위로 모아서 쓰면 이를 줄일 수 있다.
- 하지만 트레이드 오프 발생, 시간당 처리할 수 있는 메시지 수는 늘어나지만 전달되는데 걸리는 시간이 늘어난다.
### 1.2.2 스키마
- 메시지는 단순 바이트 배열일 뿐이지만, 이정한 구조를 부여하는 것이 권장된다.
- Json이나 XML << 아파치 에이브로
- 카프카는 일관적인 데이터 형식이 중요 = 메시지의 쓰기와 읽기를 분리하기 위해서
```
왜 데이터 형식이 중요할까?
데이터 형식이 일관되지 않으면 다음과 같은 문제가 발생할 수 있습니다:

1. 읽기 실패
프로듀서가 JSON으로 메시지를 작성했는데 컨슈머가 이를 Avro로 읽으려 하면 파싱 오류가 발생합니다.
데이터 구조(예: 필드 이름, 데이터 타입 등)가 일치하지 않으면 컨슈머가 데이터를 처리하지 못합니다.
2. 스키마 변경의 혼란
데이터 형식이 명확하지 않으면 스키마(데이터 구조)를 변경할 때 프로듀서와 컨슈머가 서로 동작하지 않는 문제가 발생합니다.
3. 애플리케이션 독립성 손상
Kafka의 장점은 프로듀서와 컨슈머가 독립적으로 동작할 수 있다는 것인데, 데이터 형식이 일관되지 않으면 프로듀서와 컨슈머의 결합도가 높아집니다.
```
### 1.2.3 토픽과 파티션
토픽
- 카프카에 저장되는 메시지는 토픽 단위로 분류
- 데이터베이스의 테이블이나 파일 시스템의 폴더와 같은 것

파티션
- 토픽은 여러 개의 파티션으로 나눠진다.
- Queue이 때문에 끝에 쌓이며 앞에서부터 읽힌다.
- 전체적인 관점에서 파티션에서 메시지는 순서가 보장되지 않지만 단일 파티션에서는 순서가 보장된다.
- 각 파티션은 다른 서버에 저장될 수 있으며 이에 따라 메시지에 따른 확장이 가능하여 서버 한 대 이상의 성능을 보여줄 수 있다.
- 파티션은 복재될 수 있으며 이에 따라 서로의 복제본을 서로의 서버에 저장할 수 있어 장애가 발생하는 경우 대체가 가능하다.
### 1.2.4 프로듀서오 컨슈머
프로듀셔
- 새로운 메시지 생성한다.
- 발행자 또는 작성자라고 부른다.
- 메시지는 특별한 토픽에 쓰여진다. (예를 들어 네이버 웹툰 알람, 네이버 부동산 푸시..)
- 기본적으로 프로듀셔는 생산된 메시지를 고르게 파티션에 분배한다. 하지만 메시지 키에 따라 특정 파티션으로 보내서 해당 토픽의 메시지들의 순서를 보장하기도 한다.

컨슈머
- 메시지를 읽는다.
- 구독자 또는 독자
- 컨슈머는 1개 이상의 토픽을 구독해서 여기 저장된 메시지들을 각 파티션에 쓰여진 순서대로 읽어온다.
- 컨슈머는 메시지의 오프셋을 기록해서 어느 메시지까지 읽었는지 유지한다.
![image](https://github.com/user-attachments/assets/319b4cde-3587-4783-9c01-569fc98bdb5c)
- 컨슈머는 컨슈머 그룹의 일원으로 작동한다.
  - 컨슈머 그룹 : 토픽에 저장된 데이터를 읽어오기 위해 협업하는 하나 이상의 컨슈머로 이루어져 있다.
  - 컨슈머 그룹은 각 파티션이 하나의 컨슈머에 의해서만 읽히도록 한다.
  - 남는 경우 위 그림과 컨슈머들이 나눠서 갖는다.
  - 파티션 소유권 = 파티션과 컨슈머의 대응 관계

오프셋
- 지속적으로 증가하는 값
- 카프카가 메시지를 저장할 때 각각의 메시지에 부여하는 또 다른 메타데이터
- 주어진 파티션의 각 메시지는 해당 파티션 내에서는 고유한 값을 가지며 뒤에 오는 메시지는 앞에 있는 메시지보다 그 값이 크다.
- 파티션 별로 다음 번에 사용 가능한 오프셋을 저장한다.

대량의 메시지를 갖는 토픽들을 읽기 위한 컨슈머들의 수평 확장이 가능하다. 또한 컨슈머에 장애가 발생하더라도 그룹 안의 다른 컨슈머들이 장애가 발생한 컨슈머가 읽고 있던 파티션을 재할당시킬 수 있다.
### 1.2.5 브로커와 클러스터
브로커 
- 하나의 카프카 서버
- 프로듀서로부터 메시지를 전달받아 오프셋을 할당한 뒤 디스크 저장소에 저장
- 브로커는 컨슈머의 읽기 요청 역시 처리하고 발행된 메시지를 보내준다.

클러스터
![image](https://github.com/user-attachments/assets/256aabbe-250d-478e-ba14-f13b7d47d1de)
- 브로커는 클러스터의 일부로 동작하도록 설계
- 하나의 클러스터 안에는 여러 개의 브로커가 포함됨
- 그 중 하나가 컨트롤러( = 주키퍼)
  - 파티션을 브로커에게 할당해주거나 장애가 발생한 브로커를 모니터링하는 등의 관리 기능 담당
- 파티션을 브로커 중의 하나가 관리하며 이를 파티션 리더라고 한다. 그렇기 때문에 브로커마다 각자 어떤 파티션의 리더 겸 팔로워가 될 수 있다.
- 모든 프로듀서는 리더 브로커에게 메시지를 발행하지만 컨슈머는 모든 브로커로부터 메시지를 읽어올 수 있다. (?) 약간 의문이 남아 더 찾아봤다. 보통의 경우는 리더에게 일겅온다 그 사이에
  차이가 발생하기 때문에 즉 리더는 항상 최신이지만 팔로워는 그렇지 않을 수 있기 때문이다. 그래서 책에서 약간 자세한 설명 없이 써놓은 거 같아 더 찾아보았는데 책이 약간 이상적인 이야기를 해놓은 거 같다.

보존
- 아파치 카프카의 핵심 기능 중에 일정 기간 동안 메시지를 지속성 있게 보관하는 보존 기능
- 특정 기가 동안 메시지를 보전하거나 파티션의 크기가 특정 사이즈에 도달할 땨까지 데이터를 보존
- 한도값에 도달하면 메시지는 만료되어 삭제
### 1.2.6 다중 클러스터
![image](https://github.com/user-attachments/assets/687000f1-31ba-4251-b87f-1547c560f793)
다수의 클러스터를 운용하는 것이 더 나은 경우
- 데이터 유형별 정리
- 보안 요구사항을 충족시키기 위한 격리
- 재해 복구를 대비한 다중 데이터 센터

카프카 클러스터의 복제 메커니즘은 다중 클러스트 사이가 아닌 하나의 클러스터 안에서막 작동하도록 설계되었다.

미러메이커
- 다른 클러스터로 복재하는 데 사용
- 단지 큐로 연결된 카프카 컨슈머와 프로듀서
- 두 개의 로컬 클러스터의 메시지를 하나의 직접 클러스터로 모은 뒤 다른 데이터 센터로 복사하는 모습
  ```
  1. 로컬 클러스터(Local Cluster)란?
  로컬 클러스터는 특정 지역(또는 물리적 위치)에서 데이터를 처리하기 위한 Kafka 클러스터입니다.
  주로 지역 사용자, 애플리케이션, 서비스가 생성하는 데이터를 처리하고 저장하기 위해 사용됩니다.
  로컬 클러스터는 데이터 처리 지연을 최소화하고, 지역 네트워크 대역폭을 효율적으로 사용하기 위해 중요한 역할을 합니다.
  2. 집적 클러스터(Aggregation Cluster)란?
  집적 클러스터는 여러 로컬 클러스터에서 수집된 데이터를 통합(집적)하는 Kafka 클러스터입니다.
  데이터를 중앙화하여 글로벌 분석, 백업, 데이터 복제를 용이하게 합니다.
  집적 클러스터는 보통 더 큰 스토리지 용량과 더 강력한 처리 성능을 갖춘 Kafka 클러스터입니다.
  ```
## 1.3 왜 카프카인가?
### 1.3.1 다중 프로듀셔
그냥 단순히 여러 개의 프로듀서 서버들은 모두에서 하나의 토픽에 대한 형식만 안다면 메시지를 발행할 수 있다는 것, 따라서 서버별로 컨슈머를 따로 둘 필요가 없다.
### 1.3.2 다중 컨슈머
컨슈머 그룹끼리는 상호 간겂 없이 어떠한 메시지 스트림을 읽을 수 있다. 즉 컨슈머 그룹 끼리는 메시지를 중복해서 읽을 수 있지만 그룹 내에서는 한번만 처리된다.
### 1.3.3 디스크 기반 보존
- 메시지 지속성 있게 저장
- 따라서 중간 컨슈머에 문제가 있어 해당 서버를 꺼두어도 카프카가 메시지를 저장하고 있기 때문에 유실의 위험이 없다. 그래서 다시 키면 처리되지 않은 메시지들이 처리된다.
### 1.3.4 확장성
- 사용중에서도 전체의 가용성에 영향을 주지 않으면서 확장 가능
### 1.3.5 고성능
- 지금까지 설명된 모든 기능으로 인한 고성능 
## 1.4 데이터 생태계
![image](https://github.com/user-attachments/assets/4dacbeaa-5a66-4a9c-bbc9-d69d891ce9a5)
### 1.4.1 이용사례
- 활동추적
- 메시지 교환
- 지표 및 로그 수집
- 커밋 로그
- 스트림 처리
## 1.5 카프카의 기원
### 1.5.1 링크드인이 직면한 문제
### 1.5.2 카프카의 탄생
### 1.5.3 오픈소스 및 상업적 제품
